{
  "metadata": {
    "title": "High-Level Methodology: The Operator Mindset",
    "lessonId": "lesson-3-high-level-methodology",
    "estimatedDuration": "45-60 minutes",
    "learningObjectives": [
      "Shift from craftsman to operator",
      "Master the four-phase workflow",
      "Choose effective execution modes",
      "Validate without reading every line"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "High-Level Methodology",
      "subtitle": "The Operator Mindset: From Craftsman to Orchestrator",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "Welcome to Lesson 3. We're pivoting from understanding AI agent capabilities to understanding how you work with them at scale. This isn't about writing prompts faster or reading code at superhuman speeds. It's about a fundamental mindset shift: you're no longer the person who writes every line. You're the architect who directs the system.",
        "timing": "2 minutes",
        "discussion": "Ask: Who here has tried to read and verify every line of generated code? How did that feel? What happened to your productivity?",
        "context": "In production environments with real AI coding agents, senior engineers report this mindset shift as the single biggest productivity multiplier—more than any tool feature or prompt technique.",
        "transition": "Let's start by understanding what this shift actually means for how you work."
      }
    },
    {
      "type": "concept",
      "title": "The Mindset Shift",
      "content": [
        "Your value moves up the stack: from syntax to structure",
        "You ensure quality differently: patterns over line-by-line review",
        "You validate against your mental model, not character by character",
        "You're moving from implementer to orchestrator",
        "Your focus becomes context and prompts, not implementation details"
      ],
      "speakerNotes": {
        "talkingPoints": "For 20 years, you've built your reputation on clean code and spotting subtle bugs. You owned your implementations deeply. That's not compatible with delegating 2,000 lines of code to an agent. Here's the shift: you still care about quality—you just validate it differently. Instead of reading every line, you're thinking systematically: Does this fit our architecture? Do the patterns match? Does the behavior match my mental model?",
        "timing": "3-4 minutes",
        "discussion": "Ask: What aspects of your current job depend on reading every line? What could shift to higher-level validation?",
        "context": "In our experience, engineers who resist this shift typically burn out within weeks. Those who embrace it ship 5-10x more code without quality regression.",
        "transition": "Let's contrast this with how you've been working."
      }
    },
    {
      "type": "comparison",
      "title": "Traditional vs Operator Workflow",
      "left": {
        "label": "Traditional Developer",
        "content": [
          "Write code",
          "Test code",
          "Review code",
          "Debug code",
          "Refactor code"
        ]
      },
      "right": {
        "label": "Operator Workflow",
        "content": [
          "Understand the system mentally",
          "Research context and patterns",
          "Plan the change architecturally",
          "Direct the agent precisely",
          "Validate outcomes against requirements"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Notice what disappears from the operator list: writing implementation code, reading every line, debugging syntax errors. The agent handles those. Your cognitive load shifts entirely to architectural thinking—understanding how pieces fit, what patterns matter, what risks exist. This isn't a small shift. It's restructuring your entire job.",
        "timing": "2-3 minutes",
        "discussion": "Ask: Which items on the left do you never want to do again? Which items on the right require new skills?",
        "context": "The transition is hardest in the first two weeks. After that, most engineers report they'd never go back to manual implementation.",
        "transition": "This workflow isn't linear. It's four interconnected phases."
      }
    },
    {
      "type": "visual",
      "title": "The Four-Phase Workflow",
      "component": "WorkflowCircle",
      "caption": "Systematic research, planning, execution, and validation cycle.",
      "speakerNotes": {
        "talkingPoints": "Every significant agent interaction follows this cycle: Research to ground the agent in your context, Plan to make strategic decisions about approach, Execute with the right mode for the situation, Validate outcomes against your mental model. These phases aren't steps you do once—they form a continuous loop. Validation often reveals gaps in planning, which loops you back to research.",
        "timing": "2 minutes",
        "discussion": "Ask: Which phase do you typically skip? What breaks when you do?",
        "context": "Engineers who follow this workflow report near-zero rework cycles. Those who skip phases consistently spend 3x their initial time on fixes.",
        "transition": "Let's walk through each phase in detail, starting with Research."
      }
    },
    {
      "type": "concept",
      "title": "Phase 1: Research & Grounding",
      "content": [
        "Bridge model's general knowledge with your real codebase",
        "ChunkHound for semantic code context (architectural patterns)",
        "ArguSeek for domain knowledge (APIs, frameworks, standards)",
        "Without grounding, agents hallucinate patterns and miss implementations",
        "This phase prevents the agent from inventing inconsistent solutions"
      ],
      "speakerNotes": {
        "talkingPoints": "Grounding is the bridge between the general-purpose knowledge in the model and the specific reality of your codebase. You wouldn't start coding in an unfamiliar system without reading existing implementations. Your agent needs the same. ChunkHound handles semantic code search—answering 'How is authentication handled?' instead of keyword matching. ArguSeek pulls domain knowledge directly from Google, docs, PDFs, GitHub issues. We'll cover both in detail in Lesson 5.",
        "timing": "3 minutes",
        "discussion": "Ask: How many times have agents generated code that doesn't match your patterns? That's usually a grounding failure, not a reasoning failure.",
        "context": "The best-grounded agents typically need 1-2 refinement iterations. Poorly-grounded agents need 5-10. Grounding is where the real time-save happens.",
        "transition": "With research complete, you move to planning—and here, strategy matters."
      }
    },
    {
      "type": "visual",
      "title": "Phase 2: Planning Strategies",
      "component": "PlanningStrategyComparison",
      "caption": "Choose exploration when discovering solutions, exact when implementing known approaches.",
      "speakerNotes": {
        "talkingPoints": "Planning is a strategic choice, not a single approach. When you're uncertain about the best solution, use exploration mode—frame the problem, ask the agent to research your codebase and domain knowledge, explore alternatives together. This costs more but discovers better solutions and catches architectural issues early. When you know the solution, use exact planning—be directive, define the task with specificity, provide constraints, list edge cases, define acceptance criteria. This is faster but requires upfront clarity.",
        "timing": "2-3 minutes",
        "discussion": "Ask: Think of your last project. Which approach would have worked better?",
        "context": "Most senior engineers start with exploration for new systems, then shift to exact planning once they understand the architecture deeply.",
        "transition": "Let's see what these look like in practice."
      }
    },
    {
      "type": "codeComparison",
      "title": "Planning Examples: Exploration vs Exact",
      "neutral": true,
      "leftCode": {
        "label": "Exploration Planning",
        "language": "text",
        "code": "Our Express API has inconsistent error handling—some\nendpoints return raw errors, others JSON, and stack\ntraces leak to production. Use ChunkHound to search for\n\"error handling patterns\" and \"error response format\"\nin our codebase. Use ArguSeek to research Express error\nhandling best practices and RFC 7807. Analyze what you\nfind, propose 2-3 standardization approaches with\ntrade-offs, and recommend one."
      },
      "rightCode": {
        "label": "Exact Planning",
        "language": "text",
        "code": "Add rate limiting middleware to /api/* using Redis.\nFollow the pattern in src/middleware/auth.ts.\nAuthenticated users: 1000 req/hour, anonymous: 100\nreq/hour, admins unlimited. Return 429 with Retry-After\nheader. Fail open if Redis is down - log warning but\nallow request through."
      },
      "speakerNotes": {
        "talkingPoints": "Left side: discovery mode. You're not dictating the solution; you're framing the problem space and asking the agent to research and explore. Notice it tells the agent what research tools to use and asks for trade-offs. Right side: exact mode. You've already decided the approach—Redis, specific limits per user type, explicit patterns to follow, clear failure mode. No exploration needed.",
        "timing": "3-4 minutes",
        "discussion": "Ask: Which approach would you use for a security vulnerability fix? What about architecting a new feature?",
        "context": "In production, most teams use exact planning for 70% of work (faster iteration) and exploration for 30% (architectural decisions). Early on, swap that ratio.",
        "transition": "Once you've planned, you execute. But execution has two very different modes."
      }
    },
    {
      "type": "comparison",
      "title": "Execution Modes: Supervised vs Autonomous",
      "neutral": true,
      "left": {
        "label": "Supervised Mode",
        "content": [
          "Actively monitor agent actions in real-time",
          "Maximum control and immediate error detection",
          "Use when learning agent behavior or handling critical security work"
        ]
      },
      "right": {
        "label": "Autonomous Mode",
        "content": [
          "Give agent task, let it run, check results later",
          "Enable parallel work and genuine 10x productivity",
          "Use with well-defined tasks and strong confidence in your setup"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "This is the real productivity multiplier most people miss. Yes, supervised mode gives you control. But your productivity is still tied to single-task speed. Autonomous mode is where magic happens: three agents running simultaneously on different projects, you attending meetings or cooking dinner, all while shipping code continuously. This only works if your grounding and planning are excellent. If they're not, the agent drifts and hallucinates. If they are, you can trust it completely.",
        "timing": "4-5 minutes",
        "discussion": "Ask: How many projects are you currently blocked on waiting for yourself to finish implementation? That's autonomous mode opportunity.",
        "context": "Most engineers report the real 10x gain isn't speed per task—it's working on three tasks in parallel while maintaining other responsibilities. That's a massive quality-of-life upgrade too.",
        "transition": "Execution always produces output. The question is: how do you validate what you get?"
      }
    },
    {
      "type": "concept",
      "title": "Phase 4: Validation & Iteration",
      "content": [
        "LLMs are probabilistic—rarely perfect on first pass (this is normal)",
        "Decision: iterate for refinement OR regenerate if fundamentally wrong",
        "Iterate when foundation is right but has gaps",
        "Regenerate when architecture doesn't match your mental model",
        "Use automated tests and manual testing before declaring success"
      ],
      "speakerNotes": {
        "talkingPoints": "Here's the counterintuitive reality: your job isn't to achieve perfection from the agent. Your job is to accurately identify what's wrong, then decide whether to iterate with fixes or regenerate from scratch. Code generation is cheap. Don't get attached to output. If the foundation is right but has gaps—missing edge cases, some tech debt—iterate. If something fundamental is wrong—wrong architecture, misunderstood requirements—regenerate. Usually it's faster to fix your context (the prompt, examples, constraints) than to fix the generated code.",
        "timing": "3 minutes",
        "discussion": "Ask: When was the last time you regenerated vs iterated? How did you know which was faster?",
        "context": "In production teams, the validate-and-iterate cycle typically needs 1-2 passes for exact planning tasks, 2-4 passes for exploration tasks. That's still 5-10x faster than manual implementation.",
        "transition": "Let's talk about how you actually validate."
      }
    },
    {
      "type": "concept",
      "title": "Validating Without Reading Every Line",
      "content": [
        "Your mental model is your blueprint for quick validation",
        "Check architecture: Does it match your system design?",
        "Check patterns: Are patterns consistent with grounding?",
        "Check behavior: Run code, test happy path and edge cases",
        "Spot-check risky areas where your model flags concern"
      ],
      "speakerNotes": {
        "talkingPoints": "When an agent generates 50 files, you don't review them line by line. You validate against your mental model. Does the architecture match your plan? Do the patterns align with what you grounded it with? Does the behavior satisfy your requirements? If yes, ship it. If no, identify whether it's context (regenerate) or refinement (iterate). This is faster and more reliable than character-by-character review.",
        "timing": "2-3 minutes",
        "discussion": "Ask: What parts of generated code concern you most? Those are your spot-check zones.",
        "context": "Properly prompted AI-generated code is often easier to read than hand-written code—LLMs follow patterns with mechanical precision. Your job shifts from ensuring every detail is correct to ensuring the patterns themselves are correct.",
        "transition": "This brings us to the closing principle of the workflow."
      }
    },
    {
      "type": "concept",
      "title": "The Iteration Loop",
      "content": [
        "Validation often reveals gaps in research or planning",
        "That's expected—loops back to Research or Plan phase",
        "Each cycle should narrow scope and reduce rework",
        "Few tasks go Research → Plan → Execute → Done",
        "Framework catches issues before they become expensive"
      ],
      "speakerNotes": {
        "talkingPoints": "This workflow isn't linear. It's a loop. Validation reveals issues. Some require new context or better understanding (loop to Research). Some require refined planning or approach (loop to Plan). Some just need cleanup (iterate in Execute). This is expected and normal. The value of the framework is that it catches issues at each phase instead of in production. Validation doesn't mean perfect code. It means accurate problem identification.",
        "timing": "2 minutes",
        "discussion": "Ask: Have you ever had validation reveal something that changed your architectural thinking? That's the loop working correctly.",
        "context": "Teams that embrace the loop typically see rework costs drop 60-70% compared to teams that try for perfect output on first pass.",
        "transition": "Let me close with a reality check about productivity."
      }
    },
    {
      "type": "concept",
      "title": "The Real 10x Productivity Gain",
      "content": [
        "Not about speed per task—about parallel work",
        "Run three agents simultaneously while you work on other projects",
        "Autonomous mode lets you maintain 8-hour productive stretches",
        "You can genuinely multitask in software development for first time",
        "Quality-of-life improvement: ship more code without grinding yourself"
      ],
      "speakerNotes": {
        "talkingPoints": "Most people think 10x productivity means tasks finish 10x faster. That's not it. It's about working on multiple projects simultaneously. While three agents run on different codebases, you're attending meetings, doing code review, planning architecture, living your life. Even if one task takes 30 minutes when you could hand-code it in 20, you win because you were doing something else valuable with that 30 minutes. This requires trusting your setup—excellent grounding, clear planning, proven execution patterns. But when you have that, you're not blocked by implementation anymore. You're writing code continuously at architectural speed.",
        "timing": "2-3 minutes",
        "discussion": "Ask: How many projects are you currently juggling? How many could you handle if you weren't the bottleneck for implementation?",
        "context": "Senior engineers in production environments report this as a career-changing shift. Not just more productive. Different kind of productive—strategic instead of tactical.",
        "transition": "Let's summarize the core insights."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways",
      "content": [
        "Validate through patterns, not syntax",
        "Ground research before planning architecture",
        "Choose execution mode by certainty",
        "Iterate or regenerate, not patch",
        "Productivity comes from parallel work"
      ],
      "speakerNotes": {
        "talkingPoints": "These five points are the core of the operator mindset. You're not learning a new tool or a better prompt. You're restructuring how you think about your job in an AI-assisted environment. From implementation-focused to architecture-focused. From control-through-detail to control-through-pattern. From serial task completion to parallel orchestration.",
        "timing": "2 minutes",
        "discussion": "Ask: Which takeaway challenges your current workflow most? Which excites you most about what's possible?",
        "context": "If you internalize these concepts and apply them systematically, you'll see the productivity transformation within 2-3 weeks. After that, you'll never go back.",
        "transition": "Next lesson: Lesson 4 covers the specific prompting techniques that make this workflow actually work in practice."
      }
    }
  ]
}
