{
  "metadata": {
    "title": "High-Level Methodology",
    "lessonId": "lesson-3-high-level-methodology",
    "estimatedDuration": "35-45 minutes",
    "learningObjectives": [
      "Shift from craftsman to operator",
      "Apply Research-Plan-Execute-Validate workflow",
      "Choose exploration vs exact planning",
      "Balance supervised vs autonomous execution"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "High-Level Methodology",
      "subtitle": "From Craftsman to Operator",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "This lesson covers the fundamental mindset shift required to work effectively with AI agents. We'll learn a systematic four-phase workflow that maintains quality without requiring you to read every line of generated code.",
        "timing": "1 minute",
        "discussion": "Ask: How many lines of code do you feel comfortable shipping without reading every one?",
        "context": "This is the strategic foundation that all tactical lessons build upon.",
        "transition": "Let's start with the most counterintuitive part—why you need to let go of old habits."
      }
    },
    {
      "type": "concept",
      "title": "The Psychological Shift",
      "content": [
        "Your entire career: value in the details, understanding every line",
        "Agents produce 2,000 lines—you can't own them like 200 you wrote",
        "New value: syntax → structure, loops → logic, implementation → architecture",
        "Quality assurance changes: reading every line → systematic validation",
        "Focus shifts to context you provide and prompts you craft"
      ],
      "speakerNotes": {
        "talkingPoints": "The hardest part isn't learning tools—it's letting go. You've built your reputation on understanding every line you ship. That doesn't scale with agents. Your value moves up the stack.",
        "timing": "3-4 minutes",
        "discussion": "Ask: What's the largest generated codebase you've shipped? How did you validate it?",
        "context": "Senior engineers often struggle here because their identity is tied to craftsmanship. Acknowledge this tension.",
        "transition": "This isn't about caring less about quality—it's about ensuring quality differently."
      }
    },
    {
      "type": "comparison",
      "title": "Traditional Developer vs Operator Workflow",
      "left": {
        "label": "Traditional Developer",
        "content": [
          "Write code",
          "Test code",
          "Review code",
          "Debug code",
          "Refactor code"
        ]
      },
      "right": {
        "label": "Operator",
        "content": [
          "Map the system (modules, boundaries, data flow)",
          "Research existing patterns and constraints",
          "Plan the change at architecture level",
          "Direct the agent with precise context",
          "Validate behavior against mental model"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Notice what's missing from the operator list: writing implementation code, reading every line, debugging syntax errors. The agent handles those. Your cognitive load shifts to system-level thinking.",
        "timing": "3 minutes",
        "discussion": "Ask: Which activities on the right side do you already do? Which are new?",
        "context": "Many engineers already do the operator tasks—they just do implementation too. Now you delegate implementation entirely.",
        "transition": "This doesn't mean you never read code. It means you read selectively."
      }
    },
    {
      "type": "concept",
      "title": "Selective Code Review",
      "content": [
        "50 files generated → don't review line by line",
        "Review at system level: module responsibilities, I/O contracts, state management",
        "Spot-check where mental model says 'risky' or 'complex'",
        "Properly prompted AI code is often MORE consistent than hand-written",
        "One thing doesn't change: you own the results"
      ],
      "speakerNotes": {
        "talkingPoints": "LLMs follow patterns with mechanical precision. When you provide quality patterns, they replicate perfectly. You're not sacrificing quality—you're achieving structural consistency at scale individual craftsmanship can't match.",
        "timing": "2-3 minutes",
        "discussion": "Ask: What makes you confident enough to ship code you didn't write?",
        "context": "Machines can't be held accountable—they execute instructions. Every line ships under your name.",
        "transition": "Your mental model is your blueprint. Now let's look at the process for building that model."
      }
    },
    {
      "type": "visual",
      "title": "The Four-Phase Workflow",
      "component": "WorkflowCircle",
      "caption": "Research, Plan, Execute, Validate—then iterate.",
      "speakerNotes": {
        "talkingPoints": "Every significant agent interaction should follow this pattern. Each phase has a distinct purpose, and skipping any one dramatically increases failure rate. This is your operational framework.",
        "timing": "2 minutes",
        "discussion": "Ask: Which phase do you think most engineers skip? Why?",
        "context": "Most skip Research—they jump straight to prompting. Second most skipped is Plan.",
        "transition": "Let's walk through each phase, starting with Research."
      }
    },
    {
      "type": "concept",
      "title": "Phase 1: Research (Grounding)",
      "content": [
        "Bridge between model's general knowledge and your actual context",
        "Without grounding: hallucinated patterns, inconsistent APIs, missed implementations",
        "ChunkHound: semantic code search—'How is auth handled?' not just keywords",
        "ArguSeek: domain knowledge—API docs, best practices, GitHub issues",
        "Ground in both your codebase AND domain knowledge before planning"
      ],
      "speakerNotes": {
        "talkingPoints": "You wouldn't start coding in a new codebase without learning the architecture. Your agent needs the same context. ChunkHound for code, ArguSeek for domain knowledge. We'll cover both in detail in Lesson 5.",
        "timing": "3 minutes",
        "discussion": "Ask: What happens when you prompt an agent without context about your codebase?",
        "context": "Grounding is the difference between generic code that works anywhere and code that fits your architecture.",
        "transition": "With research complete, we move to planning—and here you have a strategic choice to make."
      }
    },
    {
      "type": "visual",
      "title": "Phase 2: Plan (Strategic Decision)",
      "component": "PlanningStrategyComparison",
      "caption": "Choose exploration or exact planning based on certainty level.",
      "speakerNotes": {
        "talkingPoints": "Planning isn't one-size-fits-all. You choose between exploration (discover the solution) and exact planning (execute a known solution). Both are valid—the choice depends on your certainty level.",
        "timing": "2 minutes",
        "discussion": "Ask: How do you decide when you know enough to start coding?",
        "context": "Exploration has higher cost but discovers better solutions. Exact planning is faster but requires upfront clarity.",
        "transition": "Let's look at examples of each planning mode."
      }
    },
    {
      "type": "codeComparison",
      "title": "Exploration vs Exact Planning",
      "neutral": true,
      "leftCode": {
        "label": "Exploration Planning",
        "language": "text",
        "code": "Our Express API has inconsistent error handling—some endpoints return raw errors,\nothers JSON, and stack traces leak to production. Use ChunkHound to search for\n\"error handling patterns\" and \"error response format\" in our codebase.\nUse ArguSeek to research Express error handling best practices and RFC 7807.\nAnalyze what you find, propose 2-3 standardization approaches with trade-offs,\nand recommend one."
      },
      "rightCode": {
        "label": "Exact Planning",
        "language": "text",
        "code": "Add rate limiting middleware to /api/* using Redis.\nFollow the pattern in src/middleware/auth.ts.\nAuthenticated users: 1000 req/hour, anonymous: 100 req/hour, admins unlimited.\nReturn 429 with Retry-After header.\nFail open if Redis is down - log warning but allow request through."
      },
      "speakerNotes": {
        "talkingPoints": "Exploration: frame the problem space, let the agent research and propose. Use when the solution is unclear. Exact: be directive with specific requirements. Use when you know the solution and just need implementation.",
        "timing": "3-4 minutes",
        "discussion": "Ask: Which mode would you use for a new feature vs a bug fix?",
        "context": "If your exact plan is wrong, the generated code will be wrong. Exploration catches architectural issues early.",
        "transition": "As you plan, you're building your mental model—the blueprint for validation."
      }
    },
    {
      "type": "concept",
      "title": "Building Your Mental Model",
      "content": [
        "Not memorizing code—understanding relationships",
        "How auth flows through middleware",
        "Where validation happens vs business logic",
        "How errors propagate to the client",
        "Security boundaries and performance bottlenecks"
      ],
      "speakerNotes": {
        "talkingPoints": "Your mental model lets you validate quickly. When the agent completes, you check: 'Does this fit my mental model?' If yes, probably correct. If no, either update your model or regenerate.",
        "timing": "2 minutes",
        "discussion": "Ask: How do you currently build mental models of new codebases?",
        "context": "This is system-level thinking vs implementation-level thinking.",
        "transition": "With your plan and mental model ready, we execute—but there's a critical choice here too."
      }
    },
    {
      "type": "comparison",
      "title": "Phase 3: Execute (Two Modes)",
      "neutral": true,
      "left": {
        "label": "Supervised Mode",
        "content": [
          "Watch each action, review intermediate outputs",
          "Steer when it drifts, intervene on mistakes",
          "Maximum control and precision",
          "Cost: throughput tanks, blocked while agent works",
          "Use for: learning, security-critical code, complex exploration"
        ]
      },
      "right": {
        "label": "Autonomous Mode",
        "content": [
          "Give task from plan, check results when done",
          "You're not watching—doing other things",
          "Enable parallel work on multiple projects",
          "8-hour output with 2 hours at keyboard",
          "Requires excellent grounding and planning"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Supervised mode is your training ground—build trust and intuition. Autonomous mode is where real productivity happens. The counterintuitive truth: the gain isn't finishing tasks faster, it's working on multiple tasks simultaneously.",
        "timing": "4 minutes",
        "discussion": "Ask: What would you do with your time if agents handled implementation?",
        "context": "Even if hand-coding takes 20 min and agent takes 30, autonomous wins if you're cooking dinner instead of being blocked.",
        "transition": "Your goal is to maximize autonomous mode time. But it depends entirely on excellent grounding and planning."
      }
    },
    {
      "type": "concept",
      "title": "Phase 4: Validate (The Iteration Decision)",
      "content": [
        "LLMs are probabilistic—never expect 100% perfect on first pass",
        "Goal: identify what's wrong, then decide: iterate or regenerate?",
        "Iterate: foundation right, needs refinement (edge cases, patterns)",
        "Regenerate: fundamental flaw (architecture mismatch, wrong approach)",
        "Easier to fix context than fix generated code"
      ],
      "speakerNotes": {
        "talkingPoints": "Imperfection isn't failure—it's expected behavior. Code generation is cheap. Don't get attached. The key principle: debug your input (the prompt), not the output.",
        "timing": "3 minutes",
        "discussion": "Ask: When have you spent too long fixing generated code instead of regenerating?",
        "context": "Don't patch fundamentally broken code. Fix the context and regenerate.",
        "transition": "What does effective validation actually look like in practice?"
      }
    },
    {
      "type": "concept",
      "title": "Validation Techniques",
      "content": [
        "Run your code: be the user, test happy path, try to break it",
        "5 minutes of manual testing reveals more than 1 hour of code review",
        "Use the agent to review its own work (covered in Lesson 9)",
        "Have the agent create tests as guardrails (covered in Lesson 8)",
        "Validate behavior matches your plan and mental model"
      ],
      "speakerNotes": {
        "talkingPoints": "Nothing beats actually running your implementation. Check edge cases, error handling, performance. Automated checks (build, tests, linters) give clear signal. If they pass, manually verify behavior matches your mental model.",
        "timing": "2-3 minutes",
        "discussion": "Ask: What's your current ratio of code review time to testing time?",
        "context": "The agent is better at finding issues than generating perfect code first try. Leverage that.",
        "transition": "This workflow isn't linear—it's iterative. Let's close the loop."
      }
    },
    {
      "type": "concept",
      "title": "Closing the Loop",
      "content": [
        "Validation reveals gaps in research or flaws in plan—that's expected",
        "Value isn't executing perfectly first time—it's catching issues early",
        "Validate against mental model, not by reading every line",
        "Architecture matches plan? Patterns align with grounding? Behavior satisfies requirements?",
        "If yes, ship it. If no, identify: context problem (regenerate) or refinement (iterate)"
      ],
      "speakerNotes": {
        "talkingPoints": "The workflow is a systematic framework that catches issues before they compound. You're not validating by reading every line—you're validating against your mental model built during planning.",
        "timing": "2-3 minutes",
        "discussion": "Ask: How do you currently decide when code is ready to ship?",
        "context": "Strategy means nothing without execution. Next lesson covers the tactical prompting skills.",
        "transition": "Let's summarize the key takeaways from this methodology."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways",
      "content": [
        "Operator mindset: architecture over implementation",
        "Always: Research → Plan → Execute → Validate",
        "Mental model enables fast validation",
        "Autonomous execution maximizes true productivity",
        "Debug your input, not output"
      ],
      "speakerNotes": {
        "talkingPoints": "The shift from craftsman to operator is psychological as much as methodological. The four-phase workflow is your systematic framework. Your mental model is your validation blueprint. Autonomous mode is where real gains hide.",
        "timing": "2 minutes",
        "discussion": "Ask: Which phase will you focus on improving first?",
        "context": "Next lesson covers prompting—the tactical skills that make this strategic framework work.",
        "transition": "Next: Lesson 4: Prompting 101 - Learn specific techniques for crafting effective prompts."
      }
    }
  ]
}