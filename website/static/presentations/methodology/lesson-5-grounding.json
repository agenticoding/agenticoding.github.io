{
  "metadata": {
    "title": "Grounding: Anchoring Agents in Reality",
    "lessonId": "lesson-5-grounding",
    "estimatedDuration": "35-45 minutes",
    "learningObjectives": [
      "Ground agents with external context",
      "Apply semantic search effectively",
      "Isolate research with sub-agents",
      "Choose tools by scale"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Grounding: Anchoring Agents in Reality",
      "subtitle": "Injecting reality into the context window",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "This lesson addresses why agents confidently generate wrong solutions. The core issue: agents don't know your codebase exists. Without grounding, they hallucinate from training patterns. We'll cover techniques to anchor agents in your actual system.",
        "timing": "1 minute",
        "discussion": "Has anyone had an agent generate a solution using patterns that don't exist in your codebase?",
        "context": "This is common with authentication, database patterns, and framework-specific code where agents default to popular patterns from training data.",
        "transition": "Let's start with understanding what happens without grounding..."
      }
    },
    {
      "type": "comparison",
      "title": "Without Grounding vs With Grounding",
      "left": {
        "label": "Without Grounding",
        "content": [
          "Works from generic training patterns frozen at Jan 2025",
          "Guesses your architecture and libraries",
          "Hallucinates plausible implementations",
          "Misses current security vulnerabilities"
        ]
      },
      "right": {
        "label": "With Grounding",
        "content": [
          "Works from your actual codebase",
          "Uses current documentation",
          "Aware of recent security advisories",
          "Follows your existing patterns"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Grounding is how you inject reality into the context window. You retrieve relevant external information—codebase patterns, current docs, best practices—and feed it to the agent before generation. The left side shows agents working from stale training data. The right shows agents anchored in reality.",
        "timing": "2 minutes",
        "discussion": "What's more dangerous: an agent that fails obviously, or one that generates plausible-looking wrong code?",
        "context": "The confident wrongness is the real danger. Code reviews may miss subtle architectural mismatches.",
        "transition": "So how does an agent discover your codebase? Through agentic search..."
      }
    },
    {
      "type": "codeExecution",
      "title": "Agentic Search: Autonomous Discovery",
      "steps": [
        {
          "line": "Task: \"Fix JWT expiration validation\"",
          "highlightType": "human",
          "annotation": "Engineer provides task specification"
        },
        {
          "line": "Agent: I'll search for JWT-related code",
          "highlightType": "prediction",
          "annotation": "LLM decides to search"
        },
        {
          "line": "→ Grep(\"JWT\", \"**/*.ts\")",
          "highlightType": "execution",
          "annotation": "Tool call executed"
        },
        {
          "line": "Found in:\n  - src/auth/jwt.ts:45: export function verifyToken\n  - src/middleware/auth.ts:12: import { verifyToken }\n  - tests/auth.test.ts:8: describe('JWT verification')",
          "highlightType": "feedback",
          "annotation": "Search results returned to context"
        },
        {
          "line": "Agent: Let me read the verification logic",
          "highlightType": "prediction",
          "annotation": "LLM decides next action"
        },
        {
          "line": "→ Read(\"src/auth/jwt.ts\")",
          "highlightType": "execution",
          "annotation": "File read tool call"
        },
        {
          "line": "[verification logic shows expiration check missing]",
          "highlightType": "feedback",
          "annotation": "File content returned"
        },
        {
          "line": "Agent: Found it - verifyToken doesn't check exp claim",
          "highlightType": "prediction",
          "annotation": "LLM synthesizes finding"
        }
      ],
      "speakerNotes": {
        "talkingPoints": "This shows agentic search in action. The agent autonomously decides what to search, interprets results, and determines next steps. In small codebases under 10,000 lines, this works beautifully—2-3 searches return 5-10 files totaling 15,000 tokens.",
        "timing": "3 minutes",
        "discussion": "What happens when Grep returns 80+ files instead of 3?",
        "context": "At scale, this autonomous search breaks down. Search results flood the context window before the agent even starts reasoning about the task.",
        "transition": "Let's look at why scale breaks agentic search..."
      }
    },
    {
      "type": "visual",
      "title": "The Context Window Illusion",
      "component": "UShapeAttentionCurve",
      "caption": "Beginning and end get attention; middle gets skimmed.",
      "speakerNotes": {
        "talkingPoints": "Claude advertises 200K tokens but reliable attention spans 60-120K tokens—30-60% of advertised capacity. U-shaped attention means beginning and end get strong attention while middle gets skimmed. Fill your context and your constraints disappear into the ignored middle.",
        "timing": "3 minutes",
        "discussion": "How would you structure a prompt knowing about U-shaped attention?",
        "context": "This isn't a bug—it's transformer architecture under realistic constraints. Agentic search amplifies this: three Grep searches plus reading five files puts you at 40K tokens before finishing discovery.",
        "transition": "How do we solve this? First solution: semantic search..."
      }
    },
    {
      "type": "concept",
      "title": "Solution 1: Semantic Search",
      "content": [
        "Query by meaning, not keywords",
        "Vector embeddings capture semantic relationships",
        "\"auth middleware\" finds \"JWT validation\" code",
        "Extends scale to 100,000+ lines of code",
        "Still fills orchestrator context with results"
      ],
      "speakerNotes": {
        "talkingPoints": "Semantic search lets you query by meaning. Ask for 'authentication middleware that validates user credentials' and you get relevant code even without exact keyword matches. Vector embeddings convert code to high-dimensional vectors where similar concepts cluster together.",
        "timing": "2-3 minutes",
        "discussion": "What's the difference between finding 'auth middleware' with Grep vs semantic search?",
        "context": "IDE assistants often include semantic search built-in. CLI agents need MCP servers like Claude Context, Serena, or ChunkHound to add this capability.",
        "transition": "But semantic search still fills your orchestrator context. For true isolation, we need sub-agents..."
      }
    },
    {
      "type": "codeExecution",
      "title": "Solution 2: Sub-Agent Context Isolation",
      "steps": [
        {
          "line": "Orchestrator: \"I need to understand JWT authentication.\nDelegate research to code sub-agent.\"",
          "highlightType": "human",
          "annotation": "Orchestrator delegates research task"
        },
        {
          "line": "Sub-agent spawns with fresh isolated context",
          "highlightType": "execution",
          "annotation": "New context created"
        },
        {
          "line": "→ Semantic search: \"JWT authentication patterns\" → 12,000 tokens",
          "highlightType": "execution",
          "annotation": "Search in sub-agent context"
        },
        {
          "line": "→ Reads 3 files: jwt.ts, auth.ts, jwt.ts → 18,000 tokens",
          "highlightType": "execution",
          "annotation": "Files loaded in sub-agent context"
        },
        {
          "line": "→ Related patterns: \"token validation\" → 7,000 tokens",
          "highlightType": "execution",
          "annotation": "Additional search in sub-agent"
        },
        {
          "line": "Total consumed in sub-agent: 37,000 tokens",
          "highlightType": "feedback",
          "annotation": "Sub-agent processed full research"
        },
        {
          "line": "Sub-agent synthesizes and returns:\n\"JWT auth at src/auth/jwt.ts:45-67\nLibrary: Passport.js with JWT strategy\nIssue: Missing expiration check\"",
          "highlightType": "prediction",
          "annotation": "Synthesis returned to orchestrator"
        },
        {
          "line": "Orchestrator receives: 180 tokens instead of 37,000",
          "highlightType": "summary",
          "annotation": "Context isolation achieved"
        }
      ],
      "speakerNotes": {
        "talkingPoints": "A sub-agent is an agent invoked by another agent—like a function call for agents. The orchestrator writes a prompt describing the research task. The sub-agent executes in isolated context, returns a concise synthesis. You pay to process tokens in both contexts, but your orchestrator maintains clean context throughout.",
        "timing": "4 minutes",
        "discussion": "What's the trade-off between token cost and first-iteration accuracy?",
        "context": "The trade-off is token cost, not accuracy. You pay more but get first-iteration accuracy, which typically saves tokens compared to multiple correction cycles from polluted context.",
        "transition": "There are two architectures for sub-agents..."
      }
    },
    {
      "type": "comparison",
      "title": "Sub-Agent Architectures",
      "neutral": true,
      "left": {
        "label": "Autonomous",
        "content": [
          "Agent decides search strategy autonomously",
          "Simpler to build and maintain",
          "Works well for varied research tasks",
          "Degrades on very large codebases"
        ]
      },
      "right": {
        "label": "Structured",
        "content": [
          "Deterministic control plane defines algorithm",
          "LLM makes tactical decisions within structure",
          "Scales reliably to millions of LOC",
          "Higher cost and complexity to build"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Two valid approaches depending on scale. Autonomous agents like Claude Code's Explore decide their own strategy—flexible across tasks but degrade in large codebases. Structured agents like ChunkHound follow deterministic algorithms—the LLM ranks relevance at decision points but doesn't choose the traversal strategy.",
        "timing": "2-3 minutes",
        "discussion": "At what scale would you switch from autonomous to structured sub-agents?",
        "context": "The inflection point is around 10,000-100,000 LOC. Below that, autonomous works well. Above that, structured becomes valuable for consistency.",
        "transition": "Let's look at how to choose tools based on your codebase scale..."
      }
    },
    {
      "type": "concept",
      "title": "Tool Selection by Scale",
      "content": [
        "Under 10K LOC: Agentic search (Grep, Read, Glob)",
        "10K-100K LOC: Add semantic search or Explore agent",
        "100K+ LOC: Structured sub-agents (ChunkHound)",
        "1M+ LOC: Essential—only progressive aggregation scales"
      ],
      "speakerNotes": {
        "talkingPoints": "Your codebase size determines which grounding approach works. Small codebases work with basic tools. At 10K lines, semantic search or Explore agent extends your reach. At 100K+, structured sub-agents become valuable. At 1M+ lines, they're essential—autonomous agents show incomplete findings.",
        "timing": "2 minutes",
        "discussion": "What scale is your primary codebase? Which tools are you currently using?",
        "context": "Use 'cloc' to measure your codebase. Focus on the 'Code' column for accurate LOC counts. Most enterprise codebases are in the 100K-1M range.",
        "transition": "Code grounding is only half the picture. You also need web grounding..."
      }
    },
    {
      "type": "concept",
      "title": "Web Grounding: Same Pattern, Different Sources",
      "content": [
        "Built-in search: Works for simple queries",
        "Synthesis tools (Perplexity): Compress 15-30K to 3-8K tokens",
        "Sub-agents (ArguSeek): Isolated context + semantic state",
        "Follow-ups build on previous research",
        "Combine code + web for production systems"
      ],
      "speakerNotes": {
        "talkingPoints": "Web grounding follows the same progression as code grounding. Simple tools work initially, then hit context limits. ArguSeek is a web research sub-agent with isolated context and semantic state management—follow-up queries skip already-covered content instead of re-explaining basics.",
        "timing": "2-3 minutes",
        "discussion": "When would you use web grounding vs code grounding?",
        "context": "You need both in production. Code grounding prevents hallucinations. Web grounding gives you current best practices and security advisories.",
        "transition": "Let's see how these combine in practice..."
      }
    },
    {
      "type": "codeExecution",
      "title": "Production Pattern: Multi-Source Grounding",
      "steps": [
        {
          "line": "Task: \"Implement OAuth2 client credentials flow for our API\"",
          "highlightType": "human",
          "annotation": "Complex task requiring multiple sources"
        },
        {
          "line": "1. Code research: How does existing auth work?",
          "highlightType": "prediction",
          "annotation": "First grounding source"
        },
        {
          "line": "→ ChunkHound returns: Current session-based auth,\nmiddleware patterns, config locations (3,200 tokens)",
          "highlightType": "feedback",
          "annotation": "Code-grounded context"
        },
        {
          "line": "2. Web research: OAuth2 best practices and CVEs?",
          "highlightType": "prediction",
          "annotation": "Second grounding source"
        },
        {
          "line": "→ ArguSeek returns: RFC 6749 guidance,\nsecurity considerations, recent vulnerabilities (4,800 tokens)",
          "highlightType": "feedback",
          "annotation": "Web-grounded context"
        },
        {
          "line": "3. Implementation: Synthesize both sources",
          "highlightType": "prediction",
          "annotation": "Grounded implementation"
        },
        {
          "line": "Result: Follows existing patterns + uses 2025 standards\n+ avoids known vulnerabilities + integrates cleanly",
          "highlightType": "summary",
          "annotation": "Multi-source grounding prevents both failure modes"
        }
      ],
      "speakerNotes": {
        "talkingPoints": "In production, combine code grounding with web grounding. Code-only grounding prevents hallucinations but risks outdated patterns. Web-only grounding gives current best practices but doesn't fit your architecture. Combining both gives solutions that work for your specific system using current standards.",
        "timing": "3-4 minutes",
        "discussion": "What's an example from your work where you'd need both code and web grounding?",
        "context": "Authentication, payment processing, and security-sensitive features almost always need both. Your architecture matters, and so do current CVEs.",
        "transition": "Let's wrap up with the key takeaways..."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways",
      "content": [
        "Agents only know context contents",
        "U-shaped attention limits effective capacity",
        "Sub-agents isolate research, preserve context",
        "Choose grounding tools by scale",
        "Combine code and web grounding"
      ],
      "speakerNotes": {
        "talkingPoints": "Five key points to remember: First, without grounding agents hallucinate from training patterns. Second, advertised context capacity isn't effective capacity—U-shaped attention means middle content gets skimmed. Third, sub-agents process research in isolation and return syntheses. Fourth, match your tools to your codebase scale. Fifth, production systems need both code and web grounding.",
        "timing": "2-3 minutes",
        "discussion": "Which of these concepts was most surprising? Which will you apply first?",
        "context": "The methodology module is now complete. You have fundamental workflows, communication patterns, and context management strategies for operating agents in production.",
        "transition": "Questions before we move on?"
      }
    }
  ]
}