{
  "metadata": {
    "title": "Lesson 4: Prompting 101",
    "lessonId": "lesson-4-prompting-101",
    "estimatedDuration": "35-45 minutes",
    "learningObjectives": [
      "Understand prompting as pattern completion, not conversation",
      "Master imperative commands and specificity in prompts",
      "Apply chain-of-thought for complex multi-step tasks",
      "Structure prompts effectively using Markdown/JSON",
      "Recognize and avoid common LLM failure modes"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Prompting 101",
      "subtitle": "Pattern Completion, Not Conversation",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "This lesson shifts your mental model from 'talking to an AI' to 'initializing a pattern completion engine.' AI models predict the next token based on statistical patterns from training data. Your prompt is the pattern start; the model completes it. This fundamental distinction changes everything about how you write prompts.",
        "timing": "1 minute",
        "discussion": "Ask: 'Who's tried talking politely to an AI model? How many used 'please' and 'thank you'?' This sets up the key insight that conversational niceties waste tokens.",
        "context": "Senior engineers often apply conversational communication patterns to AI prompts, treating them like requests to a human collaborator. This lesson corrects that assumption with concrete patterns.",
        "transition": "Let's start with the most fundamental insight: what actually happens when you write a prompt."
      }
    },
    {
      "type": "concept",
      "title": "Pattern Completion, Not Requests",
      "content": [
        "You're not asking a question—you're drawing the beginning of a pattern",
        "Model predicts what naturally follows based on training data",
        "More specific pattern start = more constrained completion space",
        "Conversational tokens (please, thank you) dilute signal without clarity"
      ],
      "speakerNotes": {
        "talkingPoints": "This is the mental model shift. When you write 'Write a TypeScript function that validates email addresses,' you're not making a request to a conscious agent. You're initializing a code block pattern. The model's job is pure statistical prediction: given this pattern start, what tokens come next? The analogy: you draw the first few musical notes, and the model completes the melody based on patterns it learned.",
        "timing": "3 minutes",
        "discussion": "Ask: 'What happens to your prompt token count when you add 'Can you please help me with...'?' Have students estimate: 10-15 tokens wasted on conversational overhead that adds zero clarity.",
        "context": "In production, every token costs compute time and latency. A 500-token prompt with 50 tokens of pleasantries costs 10% more than a 450-token focused prompt with identical output quality.",
        "transition": "Now that we understand the fundamental mechanism, let's apply it to practical prompting techniques."
      }
    },
    {
      "type": "comparison",
      "title": "Imperative Commands: Weak vs Strong",
      "left": {
        "label": "Weak (Vague)",
        "content": [
          "Make a function",
          "Fix the bug",
          "Update the docs",
          "Improve performance"
        ]
      },
      "right": {
        "label": "Strong (Specific)",
        "content": [
          "Write a TypeScript function",
          "Debug the null pointer exception in UserService.ts:47",
          "Add JSDoc comments to all exported functions in auth.ts",
          "Optimize the query to use indexed columns on user_id"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Weak verbs and vague nouns force the model to guess. 'Fix the bug' could mean anything—refactor? Add validation? The model fills gaps with assumptions that may not match your intent. Strong commands are specific about what, where, and how. Notice the pattern: strong commands include file names, line numbers, explicit targets, and constraints.",
        "timing": "4 minutes",
        "discussion": "Ask: 'Pick one weak prompt and list all the ambiguities the model would need to resolve.' For 'Fix the bug'—what bug? Which file? What's broken? How should it behave? Have students rewrite it specifically.",
        "context": "In real projects, vague prompts lead to iteration cycles: model generates, you review, you clarify, model regenerates. Production code needs specificity upfront. Junior engineers often use weak prompts; senior engineers know specificity prevents rework.",
        "transition": "Specificity isn't just about being clear—it's about constraining the completion space. Let's look at how constraints work."
      }
    },
    {
      "type": "code",
      "title": "Pattern Completion in Action",
      "language": "typescript",
      "code": "// Pattern start:\n// Function 'authMiddleware' that validates JWT tokens\n\nexport async function authMiddleware(\n  req: Request,\n  res: Response,\n  next: NextFunction\n): Promise<void> {\n  const token = req.headers.authorization?.split(' ')[1];\n  if (!token) {\n    res.status(401).json({ error: 'Missing token' });\n    return;\n  }\n  // Model continues pattern here\n}",
      "caption": "The first 8 lines define the pattern. The model completes validation, error handling, and control flow based on this start.",
      "speakerNotes": {
        "talkingPoints": "Look at what this code block establishes: function name (authMiddleware), parameter types (Request, Response, NextFunction), return type (Promise<void>), and the pattern of validation logic starting. This is a complete semantic frame. The model knows what comes next because this pattern appears frequently in its training data.",
        "timing": "2-3 minutes",
        "discussion": "Ask: 'What would the model predict comes after line 12?' Have students guess the next 5-10 lines. They'll likely predict: verify JWT signature, decode payload, check expiration, attach user to request, call next(). That's the power of pattern priming.",
        "context": "This is why code examples in prompts are so powerful. A 6-line code example can communicate more intent than a 100-word explanation. It primes the pattern completion toward similar code.",
        "transition": "Constraints make patterns even more specific. Let's see what happens when constraints are missing."
      }
    },
    {
      "type": "concept",
      "title": "Constraints as Guardrails",
      "content": [
        "Unconstrained prompts = model fills gaps with assumptions",
        "Define boundaries explicitly: authentication type, endpoints, error handling",
        "Constraints reduce completion space, improve accuracy",
        "Example: 'JWT with RS256 algorithm' vs vague 'authentication'"
      ],
      "speakerNotes": {
        "talkingPoints": "Without constraints, the model has infinite reasonable choices. 'Add authentication to the API' could mean JWT, OAuth, session tokens, API keys, or mTLS. Each is valid; none is wrong without context. By defining 'Use JWT with RS256 for authentication,' you eliminate speculation. The model's completion space shrinks from infinite possibilities to a specific pattern.",
        "timing": "2-3 minutes",
        "discussion": "Ask: 'I asked a model to add authentication and it generated OAuth. I wanted JWT. Was that the model's fault or my prompt's fault?' (Answer: yours. You didn't constrain.)",
        "context": "In production code review, you'd catch this mismatch. In AI-assisted development, preventing mismatch upfront saves iteration. Constraints are a quality multiplier.",
        "transition": "Now let's look at personas—another technique for steering completion space."
      }
    },
    {
      "type": "concept",
      "title": "Personas: Vocabulary as Control",
      "content": [
        "Personas bias vocabulary distribution toward domain-specific terms",
        "Example: 'security engineer' shifts completion toward threat models, attack surface, least privilege",
        "Vocabulary acts as semantic query—retrieves different training patterns",
        "Use when: domain terminology matters. Skip when: task is straightforward"
      ],
      "speakerNotes": {
        "talkingPoints": "A persona doesn't add knowledge—it changes which knowledge the model retrieves. 'You are a security engineer' increases probability of security-specific tokens appearing in the response: threat model, attack surface, privilege escalation, validation bypass. Without the persona, the model uses generic terms like 'check for issues.' Same underlying knowledge, different vocabulary surface. Personas are token efficiency—instead of listing 20 security concepts, you trigger the 'security engineer' cluster.",
        "timing": "3 minutes",
        "discussion": "Ask: 'What terms would change if you told a model 'You are a performance engineer' vs 'You are a security engineer' when reviewing the same code?' Lead toward: performance engineer thinks in terms of throughput, latency, bottlenecks, profiling. Security engineer thinks in terms of attack surface, validation, least privilege.",
        "context": "Personas are particularly valuable when you need consistent vocabulary across multiple turns. In a security audit workflow, starting with the persona once keeps vocabulary aligned across 10+ followup questions.",
        "transition": "Personas handle vocabulary control. Now let's look at how to structure complex tasks where you need to control execution."
      }
    },
    {
      "type": "concept",
      "title": "Chain-of-Thought: Paving a Path",
      "content": [
        "CoT defines each step the model must execute in sequence",
        "You dictate the route, not just the destination",
        "Essential for multi-step operations (5+ steps) requiring accuracy",
        "Provides validation points at each stage before moving forward"
      ],
      "speakerNotes": {
        "talkingPoints": "Chain-of-Thought is explicit sequencing. Instead of asking 'Refactor this code,' you say: 'Step 1: Identify functions longer than 20 lines. Step 2: Extract each into a separate method. Step 3: Update call sites. Step 4: Verify tests still pass. Step 5: Remove the original function.' CoT prevents shortcuts and ensures the model executes methodically. This is critical for QA workflows where you need deterministic results.",
        "timing": "3 minutes",
        "discussion": "Ask: 'When would you use CoT vs just asking for the result?' Answer: CoT for multi-step operations where accuracy matters. Single-step tasks don't need it; CoT adds latency without benefit.",
        "context": "Production example: database migration workflows. You must: backup data, add migration, test migration, verify data integrity, deploy to production, monitor. CoT ensures each step completes before the next starts. Skipping a step is catastrophic.",
        "transition": "We've covered vocabulary control and execution control. Let's look at how structure organizes information to guide the model."
      }
    },
    {
      "type": "code",
      "title": "Structured Prompts: Markdown for Clarity",
      "language": "markdown",
      "code": "## Task: Build rate limiting middleware\n\n### Requirements\n- Limit requests to 100 per minute per IP\n- Return 429 when exceeded\n- Track in Redis\n\n### Implementation\n- Use token bucket algorithm\n- Store: `rate-limit:{ip}` in Redis\n- TTL: 60 seconds\n\n### Testing\n- Test: normal requests pass\n- Test: 101st request returns 429\n- Test: reset after TTL expires\n\n### Constraints\n- No external rate-limit packages\n- Must handle concurrent requests\n- Zero milliseconds of added latency",
      "caption": "Markdown structure makes requirements scannable. Headings, lists, and constraints are visually separated and semantically clear.",
      "speakerNotes": {
        "talkingPoints": "Structure matters. This same information as a paragraph would be 200 words of prose. As Markdown, it's 60 tokens of pure signal. Structure helps in two ways: (1) You parse it faster, confirming you've captured all requirements. (2) The model parses it faster, reducing token processing overhead and improving response quality.",
        "timing": "2-3 minutes",
        "discussion": "Ask: 'Count tokens in this Markdown vs how many tokens it would take to write the same requirements as prose.' This makes information density concrete.",
        "context": "Well-structured prompts reduce iteration. The model understands requirements the first time because they're unambiguous. Poor structure leads to re-prompting: 'Wait, I also needed to handle X...'",
        "transition": "Structure guides the model. But there are failure modes to avoid. Let's look at those."
      }
    },
    {
      "type": "concept",
      "title": "Avoid Negation: Affirmation Bias",
      "content": [
        "LLMs struggle with negation—attention treats NOT as a token competing for weight",
        "Problem: focus on concept mentioned ('plain text passwords') while ignoring negation",
        "Pattern: Explicit negation THEN positive opposite immediately after",
        "Risky: 'Do NOT use plain text' → Model might ignore the NOT"
      ],
      "speakerNotes": {
        "talkingPoints": "This is a mechanical limitation of how attention works. When you write 'Do NOT store passwords in plain text,' the tokens 'passwords' and 'plain text' get high attention weight because they're semantically relevant to the task. The token 'NOT' might get lower attention weight, so the model focuses on the concept (storing passwords in plain text) and misses the negation. The fix: 'Do NOT store passwords in plain text. Instead, always use bcrypt with salt rounds of 12.' Now the model sees the negation, then immediately sees the positive pattern to follow.",
        "timing": "2-3 minutes",
        "discussion": "Ask: 'Has anyone asked an AI to do something and it did the opposite?' This is often affirmation bias at work. Have them share examples and rewrite them with explicit positive opposites.",
        "context": "Security prompts are particularly vulnerable. 'Don't allow SQL injection' might generate vulnerable code if the model misses the negation. 'Prevent SQL injection by parameterizing all queries' is safer.",
        "transition": "One more failure mode: math."
      }
    },
    {
      "type": "comparison",
      "title": "Math Limitations: Predict vs Compute",
      "left": {
        "label": "Don't Do This",
        "content": [
          "Ask model: 'What's 47 × 83?'",
          "Model predicts plausible number",
          "Could be completely wrong",
          "No way to verify without external calc"
        ]
      },
      "right": {
        "label": "Do This Instead",
        "content": [
          "Ask model to write code: 'Generate function to multiply 47 × 83'",
          "Function is executed, not predicted",
          "Result is correct by definition",
          "Code can be tested and verified"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "LLMs are probabilistic text predictors. They're trained on patterns in text, not on executing algorithms. They generate plausible-sounding numbers that fail arithmetic tests. The workaround: have the model write executable code (Python, JavaScript, SQL) that performs the math. Code is deterministic; text prediction is probabilistic. This extends beyond arithmetic to any operation requiring precise computation.",
        "timing": "2-3 minutes",
        "discussion": "Ask: 'Why would you ever ask an LLM a math question directly?' They'd never do it in a calculator app. They shouldn't do it in AI prompts either. Have them identify other cases: 'count the characters in this string,' 'calculate complexity,' 'sum these numbers.'",
        "context": "Production code that relies on LLM-predicted math is a bug waiting to happen. Code review should catch this: ask 'Is this computation predicted or executed?' Predicted = risky. Executed = safe.",
        "transition": "Now let's tie all these concepts together with a summary of what makes effective prompts."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways: Effective Prompting",
      "content": [
        "Pattern completion, not conversation—skip pleasantries",
        "Imperative commands with specificity—name files, line numbers, explicit constraints",
        "Personas bias vocabulary—use for domain-specific terms, skip for simple tasks",
        "CoT for control—explicit steps for multi-step operations requiring accuracy",
        "Structure with Markdown/JSON—information density guides attention",
        "Avoid negation—state what you want, not what you don't want",
        "Don't use LLMs for math—have them write executable code instead"
      ],
      "speakerNotes": {
        "talkingPoints": "These are the operational principles for effective prompting. They're not suggestions; they're mechanical facts about how modern language models work. Pattern completion drives everything. Specificity constrains the completion space. Structure directs attention. Vocabulary biases retrieval. Negation gets missed. Math gets predicted wrong. Master these patterns and you'll write prompts that work the first time instead of requiring iteration.",
        "timing": "2 minutes",
        "discussion": "Ask: 'Which of these principles surprises you most?' Let students discuss real examples where they violated each principle and what happened.",
        "context": "In production, these principles matter because they multiply your efficiency. Vague prompts lead to 5-7 iteration cycles. Specific prompts lead to 1-2 cycles. That's 3-4x faster development.",
        "transition": "Next lesson we'll look at grounding—how to make prompts even more powerful by connecting them to real codebase context, documentation, and external knowledge."
      }
    },
    {
      "type": "concept",
      "title": "The Core Principle",
      "content": [
        "Effective prompting = precision engineering",
        "You're initializing a pattern completion engine",
        "Be specific, be structured, be explicit",
        "Every word is a token with a cost—make them count"
      ],
      "speakerNotes": {
        "talkingPoints": "This brings us back to the opening mindset shift. You're not having a conversation with an AI colleague. You're initializing a deterministic pattern completion process. The quality of your initialization determines the quality of the output. Senior engineers understand precision engineering—tight tolerances, explicit specifications, no hand-waving. Prompting requires the same discipline.",
        "timing": "1-2 minutes",
        "discussion": "Ask: 'How is prompting similar to code review? You're defining specs precisely, anticipating edge cases, checking assumptions.' This resonates with senior engineers' existing mental models.",
        "context": "End on a high note that reinforces the professional, technical nature of the material. This isn't magic; it's engineering.",
        "transition": "Questions before we move forward? If not, let's practice these principles on real examples from your codebase."
      }
    }
  ]
}