{
  "metadata": {
    "title": "Prompting 101",
    "lessonId": "lesson-4-prompting-101",
    "estimatedDuration": "35-45 minutes",
    "learningObjectives": [
      "Treat prompts as patterns",
      "Use imperative action verbs",
      "Apply personas strategically",
      "Structure prompts for clarity"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Prompting 101",
      "subtitle": "Pattern Completion, Not Conversation",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "AI coding assistants aren't conversational partners—they're sophisticated pattern completion engines. Understanding this fundamental distinction changes how you prompt. Think of prompting as drawing the beginning of a pattern. The model predicts and completes what comes next.",
        "timing": "1-2 minutes",
        "discussion": "How many of you have used ChatGPT or similar tools? How do you typically phrase your requests?",
        "context": "Most engineers approach AI tools conversationally because that's how the interfaces are designed. This lesson reframes the mental model.",
        "transition": "Let's start by understanding what prompting really is at a fundamental level."
      }
    },
    {
      "type": "concept",
      "title": "Prompting Is Pattern Completion",
      "content": [
        "Your prompt isn't a request—it's the start of a sequence",
        "The model predicts what naturally follows",
        "More specific pattern start → more constrained completion",
        "Skip pleasantries—they dilute signal without adding clarity"
      ],
      "speakerNotes": {
        "talkingPoints": "When you write a prompt, you're not asking a question or making a request. You're drawing the beginning of a pattern that the model will complete based on statistical patterns from its training data. The more specific your pattern start, the more constrained the completion space becomes.",
        "timing": "2-3 minutes",
        "discussion": "Think about autocomplete in your IDE. How is that similar to what LLMs do?",
        "context": "This is the foundational mental model. Everything else in prompting builds on understanding that you're initializing a pattern completion engine.",
        "transition": "Now let's see this in action with imperative commands."
      }
    },
    {
      "type": "codeComparison",
      "title": "Imperative Commands: Ineffective vs Effective",
      "leftCode": {
        "label": "Ineffective",
        "language": "text",
        "code": "Could you help me write a function\nto validate email addresses?\nThanks in advance!"
      },
      "rightCode": {
        "label": "Effective",
        "language": "text",
        "code": "Write a TypeScript function that\nvalidates email addresses per RFC 5322.\nHandle edge cases:\n- Multiple @ symbols (invalid)\n- Missing domain (invalid)\n- Plus addressing (valid)\n\nReturn { valid: boolean, reason?: string }"
      },
      "speakerNotes": {
        "talkingPoints": "The ineffective prompt wastes tokens on pleasantries and gives no constraints. The effective prompt draws the beginning of a precise pattern: TypeScript function signature, validation rules, return type. The model completes this pattern with matching code.",
        "timing": "3-4 minutes",
        "discussion": "What information is missing from the left prompt that the model would have to guess?",
        "context": "In production, vague prompts lead to code that compiles but doesn't meet requirements. Specific prompts reduce iteration cycles from 5+ to 1-2.",
        "transition": "Let's look at how action verbs establish clear patterns."
      }
    },
    {
      "type": "codeComparison",
      "title": "Action Verbs and Specificity",
      "leftCode": {
        "label": "Weak",
        "language": "text",
        "code": "Make a function\n\nFix the bug\n\nUpdate the docs\n\nImprove performance"
      },
      "rightCode": {
        "label": "Strong",
        "language": "text",
        "code": "Write a function\n\nDebug the null pointer exception\nin UserService.ts:47\n\nAdd JSDoc comments to all\nexported functions in auth.ts\n\nOptimize the query to use\nindexed columns"
      },
      "speakerNotes": {
        "talkingPoints": "Strong verbs establish clear patterns. 'Write' is more specific than 'make'. 'Debug' with a file and line number is more actionable than 'fix'. Specificity compounds effectiveness—the more precise, the better the completion.",
        "timing": "2-3 minutes",
        "discussion": "What's the difference between 'fix the bug' and 'debug the null pointer exception in UserService.ts:47'?",
        "context": "Think of weak verbs as fuzzy pattern starts that could lead anywhere. Strong verbs with specifics constrain the completion space dramatically.",
        "transition": "Now let's talk about using constraints as guardrails."
      }
    },
    {
      "type": "codeComparison",
      "title": "Constraints as Guardrails",
      "leftCode": {
        "label": "Unconstrained",
        "language": "text",
        "code": "Add authentication to the API"
      },
      "rightCode": {
        "label": "Constrained",
        "language": "text",
        "code": "Add JWT authentication to the API:\n- Do NOT modify existing session middleware\n- Use jsonwebtoken library\n- Protect all /api/v1/* endpoints\n  except /api/v1/auth/login\n- Token expiry: 24 hours\n- Store user ID and role in payload\n- Return 401 for missing/invalid tokens"
      },
      "speakerNotes": {
        "talkingPoints": "Without constraints, the model fills gaps with assumptions. What authentication? JWT? OAuth? Session tokens? Which endpoints? The constrained version defines the completion space completely. No guessing required.",
        "timing": "3 minutes",
        "discussion": "What assumptions would you make if given the unconstrained prompt? How might those differ from a colleague's assumptions?",
        "context": "In production, ambiguous prompts lead to rework. Constraints prevent the model from making assumptions that don't match your requirements.",
        "transition": "Next, let's explore how personas can bias the model's vocabulary."
      }
    },
    {
      "type": "concept",
      "title": "Assigning Personas Strategically",
      "content": [
        "Personas bias vocabulary distribution, not capability",
        "Use when domain-specific terminology matters",
        "Skip when task is straightforward",
        "Vocabulary is the control interface for semantic retrieval"
      ],
      "speakerNotes": {
        "talkingPoints": "Writing 'You are a security engineer' increases the probability of security-specific terms like 'threat model', 'attack surface', 'least privilege'. These terms act as semantic queries during attention, retrieving different training patterns than generic terms. The persona is a vocabulary shortcut.",
        "timing": "2-3 minutes",
        "discussion": "What domain-specific vocabularies do you work with? How might persona prompts help?",
        "context": "The persona didn't add knowledge—it changed which knowledge gets retrieved by shifting vocabulary. This principle applies to code search tools, research agents, and vector databases too.",
        "transition": "Let's see a concrete example of persona prompting."
      }
    },
    {
      "type": "codeComparison",
      "title": "Persona Prompting: Generic vs Focused",
      "leftCode": {
        "label": "Generic",
        "language": "text",
        "code": "Review this authentication code\nfor issues."
      },
      "rightCode": {
        "label": "Security-Focused",
        "language": "text",
        "code": "You are a security engineer\nconducting a code review.\n\nReview this authentication code.\nFlag vulnerabilities:\nSQL injection, XSS, auth bypasses,\nsecrets in code.\n\nAssume adversarial input and\nuntrusted networks."
      },
      "speakerNotes": {
        "talkingPoints": "The generic prompt yields generic advice like 'Check for proper validation'. The security-focused prompt yields targeted security analysis identifying specific vulnerabilities with mitigation strategies. Same code, different vocabulary, different results.",
        "timing": "2-3 minutes",
        "discussion": "What other personas might be useful for code review? Performance engineer? Accessibility expert?",
        "context": "Use personas when you need to trigger domain-specific vocabulary clusters. Skip them for straightforward tasks where the overhead isn't worth it.",
        "transition": "Now let's look at Chain-of-Thought for complex tasks."
      }
    },
    {
      "type": "codeComparison",
      "title": "Chain-of-Thought: Paving a Clear Path",
      "leftCode": {
        "label": "Without CoT",
        "language": "text",
        "code": "Debug the failing test in\nUserService.test.ts"
      },
      "rightCode": {
        "label": "With CoT",
        "language": "text",
        "code": "Debug the failing test in\nUserService.test.ts:\n\n1. Read the test file, identify\n   which test is failing\n2. Analyze test assertion:\n   expected vs actual values\n3. Trace code path through\n   UserService to find the bug\n4. Explain root cause\n5. Propose fix\n\nProvide conclusions with evidence."
      },
      "speakerNotes": {
        "talkingPoints": "Chain-of-Thought defines each step the model must execute in sequence. You're not asking for reasoning—you're dictating the path. The model can't skip steps or take shortcuts. Errors surface early rather than compounding.",
        "timing": "3-4 minutes",
        "discussion": "When have you needed to debug a problem step-by-step? How did explicit steps help?",
        "context": "CoT is particularly powerful for QA workflows where you need methodical execution. Modern models handle simple tasks without CoT, but multi-step operations (5+ steps) require explicit guidance.",
        "transition": "Let's look at how structure organizes information."
      }
    },
    {
      "type": "code",
      "title": "Structure with Markdown",
      "language": "markdown",
      "code": "# Task: Implement OAuth 2.0 Client Credentials\n\n## Requirements\n- Support multiple authorization servers\n- Cache tokens until expiry (Redis)\n- Auto-retry on 401 with token refresh\n\n## Implementation Steps\n1. Create OAuthClient class with getToken()\n2. Implement token caching with TTL\n3. Add retry logic with exponential backoff\n\n## Constraints\n- Use axios for HTTP requests\n- No global state—client must be instantiated",
      "caption": "Markdown organizes requirements, steps, and constraints clearly",
      "speakerNotes": {
        "talkingPoints": "Different formats have different information density. Markdown is highly information-dense: headings, lists, and code blocks provide clear semantic structure with minimal overhead. The structure makes requirements scannable and draws attention to distinct sections.",
        "timing": "2-3 minutes",
        "discussion": "How do you typically structure complex requirements in your current workflow?",
        "context": "Well-structured prompts help the model parse intent and respond with matching structure. This matters for both token efficiency and grounding.",
        "transition": "Now let's cover common pitfalls to avoid."
      }
    },
    {
      "type": "codeComparison",
      "title": "Avoiding Negation Issues",
      "leftCode": {
        "label": "Risky",
        "language": "text",
        "code": "Write a user registration endpoint.\nDo NOT store passwords in plain text."
      },
      "rightCode": {
        "label": "Better",
        "language": "text",
        "code": "Write a user registration endpoint.\n\nPassword handling:\nDo NOT store passwords in plain text.\nInstead, always store passwords\nas hashed values.\nUse bcrypt with 10 salt rounds\nbefore storing."
      },
      "speakerNotes": {
        "talkingPoints": "LLMs struggle with negation because attention mechanisms treat 'NOT' as just another token. The model might miss 'NOT' and focus on 'passwords' + 'plain text'. The fix: state the negation, then immediately provide the positive opposite with concrete implementation details.",
        "timing": "3 minutes",
        "discussion": "Have you ever seen an AI ignore a 'do not' instruction? What happened?",
        "context": "This is called 'affirmation bias'—the model's token generation leans toward positive selection rather than negative exclusion.",
        "transition": "There's one more critical limitation to understand."
      }
    },
    {
      "type": "codeComparison",
      "title": "LLMs Can't Do Math",
      "leftCode": {
        "label": "Don't Do This",
        "language": "text",
        "code": "Calculate the optimal cache size\nfor 1M users with 2KB average\ndata per user, assuming 80%\nhit rate and 4GB available memory."
      },
      "rightCode": {
        "label": "Do This Instead",
        "language": "text",
        "code": "Write a Python function that\ncalculates optimal cache size.\n\nInputs:\n- user_count: number of users\n- avg_data_per_user_kb: KB per user\n- hit_rate: 0.0 to 1.0\n- available_memory_gb: memory in GB\n\nReturn optimal cache size in MB.\nInclude unit tests."
      },
      "speakerNotes": {
        "talkingPoints": "LLMs are probabilistic text predictors, not calculators. They're terrible at arithmetic. The model will generate plausible-sounding numbers that may be completely wrong. Instead, have the model write code that does the math—then the code can be verified.",
        "timing": "2-3 minutes",
        "discussion": "What other tasks should you NOT ask an LLM to do directly?",
        "context": "This applies to any deterministic computation: date calculations, financial formulas, statistical analysis. Always have the model generate code, not compute results.",
        "transition": "Let's wrap up with the key takeaways."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways",
      "content": [
        "Prompting is pattern completion",
        "Personas bias vocabulary distribution",
        "CoT paves explicit paths",
        "Avoid negation—state positives",
        "LLMs can't do math"
      ],
      "speakerNotes": {
        "talkingPoints": "Effective prompting is precision engineering. You're not having a conversation—you're initializing a pattern completion engine. Be specific, be structured, be explicit. Use personas to trigger domain vocabulary, CoT for complex tasks, and always have the model write code for calculations.",
        "timing": "2 minutes",
        "discussion": "What's one prompting habit you'll change based on this lesson?",
        "context": "These principles apply whether you're using ChatGPT, Claude, Copilot, or any other AI coding assistant.",
        "transition": "Next lesson, we'll explore Grounding—how to provide context that helps the model understand your codebase."
      }
    }
  ]
}