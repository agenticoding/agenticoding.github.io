{
  "metadata": {
    "title": "Course Introduction",
    "lessonId": "intro",
    "estimatedDuration": "20-30 minutes",
    "learningObjectives": [
      "Adopt AI operator mindset",
      "Understand Research-Plan-Execute-Validate workflow",
      "Recognize AI amplification patterns",
      "Apply production-ready methodology"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Agentic Coding",
      "subtitle": "Operator training for AI coding agents",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "Welcome to Agentic Coding. This isn't a course about AI theory or prompt templates—it's operator training. Over 77,000 organizations have adopted GitHub Copilot, and 51% of developers use AI tools daily. But 66% say AI solutions are 'almost right, but not quite.' The problem isn't the tools—it's the operating model.",
        "timing": "1-2 minutes",
        "discussion": "Quick show of hands: How many of you have used AI coding assistants? How many have felt frustrated by 'almost right' code?",
        "context": "Research shows developers without proper methodology are 19% slower with AI tools, while practitioners using systematic approaches report up to 10x efficiency gains. The difference is operator skill.",
        "transition": "Let's start with the core problem most engineers face."
      }
    },
    {
      "type": "concept",
      "title": "The Problem: Wrong Mental Model",
      "content": [
        "Treating AI agents like junior developers",
        "Waiting for them to 'understand'",
        "Fixing code line-by-line",
        "Fighting context limits reactively"
      ],
      "speakerNotes": {
        "talkingPoints": "Most engineers approach AI agents like they would a junior teammate—explaining context, waiting for understanding, then fixing output incrementally. This mental model is fundamentally wrong. AI agents aren't teammates. They're power tools. The operating model needs to match.",
        "timing": "2-3 minutes",
        "discussion": "What behaviors have you noticed in yourself when working with AI coding assistants? Any patterns that feel inefficient?",
        "context": "This wrong mental model explains the '66% almost right' statistic. Engineers expect understanding where there's only statistical prediction. They expect initiative where there's only execution.",
        "transition": "So what's the correct model? Let's look at what this course actually teaches."
      }
    },
    {
      "type": "concept",
      "title": "What This Course Is",
      "content": [
        "Operator training for AI coding agents",
        "Systematic methodology for production use",
        "Real-world patterns, not toy demos",
        "Engineering judgment with stochastic tools"
      ],
      "speakerNotes": {
        "talkingPoints": "This is operator training. Like learning to operate power tools in construction, you'll learn systematic approaches for research, planning, execution, and validation. No hand-holding, no toy examples. We assume you know how to engineer software—we're teaching you how to orchestrate agents that execute it.",
        "timing": "2 minutes",
        "discussion": "How do you currently decide when to use AI assistance versus writing code yourself?",
        "context": "The course assumes 3+ years professional engineering experience. If you don't have production experience, start there first. AI agents amplify your existing skills—they don't replace fundamentals.",
        "transition": "Let's be clear about what this course is not."
      }
    },
    {
      "type": "concept",
      "title": "What This Course Isn't",
      "content": [
        "Not AI theory—just enough to operate",
        "Not prompt templates—principles, not copying",
        "Not replacement for fundamentals",
        "Not for beginners without production experience"
      ],
      "speakerNotes": {
        "talkingPoints": "We cover enough internals to operate effectively, nothing more. Copying prompts doesn't work—understanding principles does. You still need architecture, design patterns, and system design skills. AI agents amplify what you already know.",
        "timing": "2 minutes",
        "discussion": "Why do you think copying prompts from tutorials often fails in real projects?",
        "context": "The target audience is senior engineers who have already tried AI assistants and hit frustration points. If that's you, you're in the right place.",
        "transition": "Here's the core methodology you'll learn."
      }
    },
    {
      "type": "codeExecution",
      "title": "The Systematic Approach",
      "steps": [
        {
          "line": "Research",
          "highlightType": "human",
          "annotation": "Ground agents in codebase patterns and domain knowledge"
        },
        {
          "line": "Plan",
          "highlightType": "prediction",
          "annotation": "Design changes strategically—explore or be directive"
        },
        {
          "line": "Execute",
          "highlightType": "execution",
          "annotation": "Run agents supervised or autonomous based on trust"
        },
        {
          "line": "Validate",
          "highlightType": "feedback",
          "annotation": "Verify against your mental model"
        },
        {
          "line": "Iterate or Regenerate",
          "highlightType": "summary",
          "annotation": "Loop based on validation results"
        }
      ],
      "speakerNotes": {
        "talkingPoints": "This four-phase approach is the core of the methodology: Research to ground agents, Plan to design changes, Execute with appropriate supervision, Validate against your mental model. Then iterate or regenerate as needed. Every module in this course maps to these phases.",
        "timing": "3-4 minutes",
        "discussion": "Which of these phases do you currently do well? Which do you skip or rush through?",
        "context": "Most engineers jump straight to Execute without Research or Planning. This leads to context fights and 'almost right' code. The methodology front-loads context to reduce iteration cycles.",
        "transition": "Let's look at the concrete outcomes you'll achieve."
      }
    },
    {
      "type": "concept",
      "title": "What You'll Gain",
      "content": [
        "Onboard to codebases 5-10x faster",
        "Refactor reliably with test-driven validation",
        "Debug by delegating log analysis",
        "Plan features with parallel sub-agents"
      ],
      "speakerNotes": {
        "talkingPoints": "These aren't theoretical gains. Onboarding to unfamiliar codebases with agentic research is dramatically faster. Refactoring with test-driven validation catches regressions early. Debugging by delegating log and database analysis to agents frees your attention for root cause analysis.",
        "timing": "2-3 minutes",
        "discussion": "Which of these outcomes would have the biggest impact on your current work?",
        "context": "These capabilities build on each other. Agentic research skills apply to onboarding, debugging, and planning. Test-driven validation applies to refactoring and feature development.",
        "transition": "Now for the deeper truth about what this course is really about."
      }
    },
    {
      "type": "comparison",
      "title": "AI Agents as Amplifiers",
      "left": {
        "label": "Bad Patterns Amplified",
        "content": [
          "8x more code duplication",
          "Technical debt compounds",
          "Poor architecture propagates",
          "Anti-patterns become standard"
        ]
      },
      "right": {
        "label": "Good Patterns Amplified",
        "content": [
          "Clean architecture spreads",
          "Test coverage compounds",
          "Best practices propagate",
          "Quality becomes standard"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "AI agents are amplifiers—of your architectural clarity, your testing discipline, your code patterns. Good or bad, they compound what exists. Research shows AI code has 8x more duplication—not because agents create it, but because they amplify existing patterns in your codebase.",
        "timing": "3-4 minutes",
        "discussion": "What patterns in your codebase would you want amplified? Which ones would you definitely not want amplified?",
        "context": "This is why engineering fundamentals matter more with AI tools, not less. Every accepted line becomes pattern context for future agents. Your judgment determines which direction the exponential curve bends.",
        "transition": "This leads to the most important point of this introduction."
      }
    },
    {
      "type": "concept",
      "title": "You Are the Circuit Breaker",
      "content": [
        "Every accepted line becomes pattern context",
        "Your review shapes future agent output",
        "Engineering judgment is non-negotiable",
        "The tools changed—fundamentals didn't"
      ],
      "speakerNotes": {
        "talkingPoints": "You are the circuit breaker. Every line of code you accept becomes context that shapes future agent output. Your engineering judgment—in review, in architecture, in pattern design—determines whether quality compounds or degrades.",
        "timing": "2-3 minutes",
        "discussion": "How does this change how you think about code review for AI-generated code versus human-written code?",
        "context": "This is about rigorous engineering with tools that happen to be stochastic systems. The fundamentals—architecture, testing, code review—matter more now, not less.",
        "transition": "Let's look at the course structure so you know what's ahead."
      }
    },
    {
      "type": "concept",
      "title": "Course Structure",
      "content": [
        "Module 1: Fundamentals—mental models, architecture",
        "Module 2: Methodology—prompting, grounding, workflows",
        "Module 3: Practical Techniques—onboarding, testing, debugging"
      ],
      "speakerNotes": {
        "talkingPoints": "The course is structured as a reference manual, not a traditional course with exercises. Read sequentially first to build the mental models, then return to specific lessons as you encounter relevant situations. The value comes from having the right models when you need them.",
        "timing": "2 minutes",
        "discussion": "Based on the course structure, which module are you most looking forward to?",
        "context": "Module 1 establishes what LLMs and agents actually are—not marketing, but technical reality. Module 2 covers the how of working with them effectively. Module 3 applies everything to real workflows.",
        "transition": "Let's wrap up with key takeaways before diving into Lesson 1."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways",
      "content": [
        "AI agents are power tools",
        "Research-Plan-Execute-Validate methodology",
        "Agents amplify existing patterns",
        "You are the circuit breaker"
      ],
      "speakerNotes": {
        "talkingPoints": "Four things to remember: AI agents are power tools requiring operator skill, not teammates needing management. The systematic approach is Research, Plan, Execute, Validate. Agents amplify existing patterns—good and bad. And you are the circuit breaker that determines quality.",
        "timing": "2 minutes",
        "discussion": "Which of these takeaways most challenges your current approach to AI coding assistants?",
        "context": "These principles are the foundation for everything that follows. Keep them in mind as you work through the course and apply the techniques to your own projects.",
        "transition": "Ready to start? Let's begin with Lesson 1: How LLMs Work, where we'll understand the machinery before operating it."
      }
    }
  ]
}