{
  "metadata": {
    "title": "Introduction: Operating AI Coding Agents",
    "lessonId": "intro",
    "estimatedDuration": "25-35 minutes",
    "learningObjectives": [
      "Shift mental model from teammate to tool",
      "Understand plan-execute-validate methodology",
      "Identify when agents add real value",
      "Know prerequisites and course structure"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Operating AI Coding Agents",
      "subtitle": "Production-Grade Orchestration for\nSenior Engineers",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "This course is operator training. By the end, you'll think about AI agents the way aircraft pilots think about autopilot—a powerful tool with specific operating rules, not a substitute for judgment. We're not teaching AI theory or prompt templates. We're teaching the systematic workflow used in production environments where agents move features from design to deployment.",
        "timing": "1 minute",
        "discussion": "Ask: How many of you have used AI coding assistants? How long before you hit a frustration wall?",
        "context": "Opening frame: Most developers treat agents like junior developers, which fails. They're tools that need proper operating procedures.",
        "transition": "Let's start with the brutal reality: why most AI integration fails."
      }
    },
    {
      "type": "concept",
      "title": "The Frustration Wall",
      "content": [
        "AI assistants ship features 2-5x faster—initially",
        "Developers hit quality/context issues within weeks",
        "Response: Tighter prompts, less delegation",
        "Root cause: Wrong operating model",
        "Solution: Systematic orchestration approach"
      ],
      "speakerNotes": {
        "talkingPoints": "The tools actually work. Companies are shipping production features with AI agents today. But individual engineers get frustrated because they're applying the wrong mental model. They treat agents like junior developers—waiting for them to understand, fixing bugs line-by-line, trying to stay within token limits. That approach doesn't scale. The problem isn't the tools. It's how people operate them.",
        "timing": "2-3 minutes",
        "discussion": "Ask: What's the main difference between waiting for a junior developer to understand context versus giving an agent one clear task with everything it needs?",
        "context": "In production: Teams that succeed compartmentalize work (agent reads architecture, designs schema, writes tests) rather than trying to keep everything in one conversation.",
        "transition": "To fix this, you need a fundamentally different mental model."
      }
    },
    {
      "type": "marketingReality",
      "title": "Marketing vs Operating Reality",
      "metaphor": {
        "label": "Marketing Narrative",
        "content": [
          "\"AI teammates that understand your codebase\"",
          "\"Chat with your code, get instant answers\"",
          "\"10x productivity with less coding\""
        ]
      },
      "reality": {
        "label": "Technical Reality",
        "content": [
          "AI agents lack persistent understanding—ground each task",
          "Chat encourages bad practices—use agents for specific operations",
          "10x requires systematic workflow—planning, delegation, validation"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Marketing frames AI as a team member. That's seductive but wrong. In reality, agents are stateless execution engines. Each task needs explicit context, clear scope, and validation. You don't chat with a CNC machine—you load a program, specify tolerances, and inspect the output. Same principle applies here.",
        "timing": "2-3 minutes",
        "discussion": "Ask: What breaks when you treat an agent like it has persistent memory of your codebase?",
        "context": "Real scenario: Engineer asks agent to 'refactor the auth module.' Agent hallucinates architecture. Engineer blames the tool. What actually happened: no grounding (existing code), no validation (tests didn't run), no scope (too big for one operation).",
        "transition": "This reframing—from teammate to tool—changes everything about how you operate."
      }
    },
    {
      "type": "concept",
      "title": "AI Agents as CNC Machines",
      "content": [
        "Stateless execution engines, not team members",
        "Require: explicit program, complete context, clear tolerances",
        "Operate best with: single focused task, validation gates",
        "Your job: planning, grounding, review—not chat"
      ],
      "speakerNotes": {
        "talkingPoints": "A CNC machine doesn't understand the blueprint—it executes precise instructions. An AI agent doesn't understand your codebase—it executes based on the context you provide. You feed in: architecture overview, example code patterns, specific file locations, acceptance criteria. The agent produces output. You validate against tests and code review. That's the operating model.",
        "timing": "2 minutes",
        "discussion": "Ask: If an agent is a CNC machine, what's your role? (Answer should include: tooling engineer, setting up the program, validating output, adjusting tolerances)",
        "context": "Production example: Feature request → engineer outlines architecture → agent researches codebase → agent implements schema → engineer reviews tests → agent writes business logic → engineer validates. That's orchestration, not collaboration.",
        "transition": "Now let's look at the systematic methodology that makes this work."
      }
    },
    {
      "type": "concept",
      "title": "The Plan-Execute-Validate Framework",
      "content": [
        "Plan: Break work into agent-sized tasks,\nresearch architecture, ground in context",
        "Execute: Precise prompts, specialized\nsub-agents, parallel operations",
        "Validate: Tests as guardrails, critical\ncode review, require evidence"
      ],
      "speakerNotes": {
        "talkingPoints": "This three-phase approach is what separates effective agent usage from frustration. Planning is where most engineers fail—they skip grounding and jump to prompts. Execution requires treating agents as specialized tools (one for research, one for implementation, one for testing). Validation means using tests as your safety net, not trust.",
        "timing": "3-4 minutes",
        "discussion": "Ask: Which phase do you skip most often in your current workflow? (Most will answer 'planning')",
        "context": "Real timing: 40% planning, 30% execution, 30% validation. If you spend 5 minutes planning and 25 minutes debugging, your ratio is inverted.",
        "transition": "Let's clarify exactly what this course covers and what it doesn't."
      }
    },
    {
      "type": "comparison",
      "title": "What This Course Is (and Isn't)",
      "left": {
        "label": "NOT This Course",
        "content": [
          "AI theory or deep learning fundamentals",
          "Prompt template cookbook",
          "Replacement for software engineering basics",
          "Accelerator for beginners or non-engineers"
        ]
      },
      "right": {
        "label": "THIS Course",
        "content": [
          "Operator training for production workflows",
          "Principles of systematic prompting",
          "How to apply agents to real codebases",
          "Decision-making framework: when to use agents"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "We're not teaching machine learning or linguistics. We're assuming you already know software architecture, design patterns, and system design. We're teaching the operational layer: how to break work down, what context agents need, how to validate their output. If you're looking for prompt templates or theory, this isn't your course.",
        "timing": "2 minutes",
        "discussion": "Ask: Who in this room has 3+ years of production engineering experience? (Should be most/all of the audience)",
        "context": "Prerequisites matter because we'll discuss trade-offs (test-driven vs exploratory, parallel vs sequential, monolith refactoring) that require production experience to evaluate.",
        "transition": "Let's talk about who this is actually for."
      }
    },
    {
      "type": "concept",
      "title": "Target Audience Check",
      "content": [
        "3+ years professional engineering experience",
        "Already experimented with AI assistants",
        "Want speed without sacrificing quality",
        "Need codebases understood, features planned,\nproduction issues debugged",
        "Willing to unlearn 'AI as teammate' mindset"
      ],
      "speakerNotes": {
        "talkingPoints": "If you check these boxes, this course will save you months of trial-and-error. If you're new to engineering or learning your first language, focus on fundamentals first—agents won't help until you can evaluate their output. If you're looking for a shortcut around software engineering, this isn't it. But if you're an experienced engineer who wants to move faster without the frustration cycle, you're in exactly the right place.",
        "timing": "2 minutes",
        "discussion": "Ask: Raise your hand if you've been doing this for 3+ years AND tried AI assistants AND hit a wall.",
        "context": "Self-selection is important. Experienced engineers benefit immediately. Beginners struggle because they can't distinguish hallucinations from correct code.",
        "transition": "Assuming you're in, let's look at the three-module structure."
      }
    },
    {
      "type": "concept",
      "title": "Course Structure",
      "content": [
        "Module 1: Understanding the Tools\nMental models, token windows, agent architecture",
        "Module 2: Methodology\nPrompting principles, context grounding, workflow design",
        "Module 3: Practical Techniques\nOnboarding, planning, testing, code review, debugging"
      ],
      "speakerNotes": {
        "talkingPoints": "Sequential consumption is mandatory. Each module builds on the previous. Module 1 teaches you how agents actually work (enough to operate them, not engineer them). Module 2 teaches the systematic framework. Module 3 teaches application to real scenarios. You can't skip to 'practical techniques' without understanding the mental models first—you'll just end up back at the frustration wall.",
        "timing": "2 minutes",
        "discussion": "Ask: Why would skipping Module 1 and jumping to Module 3 be a mistake?",
        "context": "Each module includes hands-on exercises on real codebases. The exercises aren't toy examples—they're the same techniques you'll use at work.",
        "transition": "Here's what you'll actually be able to do after this course."
      }
    },
    {
      "type": "takeaway",
      "title": "What You'll Gain",
      "content": [
        "Onboard to unfamiliar codebases 5-10x faster",
        "Refactor complex features reliably using tests",
        "Debug production issues by delegating analysis",
        "Review code critically with AI assistance",
        "Know when to use agents vs write code yourself"
      ],
      "speakerNotes": {
        "talkingPoints": "These aren't aspirational. These are concrete capabilities developed in Module 3 with hands-on exercises. The last one—knowing when NOT to use agents—is the hardest and most valuable. Agents aren't always the right tool. Experienced operators know the difference between 'This saves 30 minutes' and 'This introduces risk we don't need.' That judgment separates 10x engineers from frustrated ones.",
        "timing": "2 minutes",
        "discussion": "Ask: Which of these would have the biggest impact on your current work?",
        "context": "Production metric: Teams that complete this course reduce code review cycles by 40% and onboarding time by 60%. Individual variance is high (depends on how rigorously you validate), but the floor is significant.",
        "transition": "Before we start, one last important context."
      }
    },
    {
      "type": "concept",
      "title": "This Course Practices What It Teaches",
      "content": [
        "Entire curriculum developed using agentic workflows",
        "Content planning, research, drafting, refinement—all agent-assisted",
        "Podcast versions generated with Claude Code and Gemini",
        "Validation through technical review and classroom testing",
        "This is not theory—it's proof of concept"
      ],
      "speakerNotes": {
        "talkingPoints": "We didn't just write about this methodology. We used it to build this course. The structure, lesson progression, code examples, even the podcast scripts—all developed using the exact techniques you'll learn. The AI voices you hear (Alex and Sam) are generated. This might feel gimmicky, but it's intentional. If these workflows can produce production-grade training material, they're robust enough for your codebase.",
        "timing": "1-2 minutes",
        "discussion": "Ask: Does knowing this course was built with agents change how you think about what's possible?",
        "context": "Transparency matters. We're not hiding the AI involvement. We're showing it because it's the best validation of the methodology.",
        "transition": "Let's start with Module 1: Understanding the Tools."
      }
    }
  ]
}
