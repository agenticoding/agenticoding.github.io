{
  "metadata": {
    "title": "Spec Driven Development",
    "lessonId": "lesson-12-spec-driven-development",
    "estimatedDuration": "30-40 minutes",
    "learningObjectives": [
      "Apply DRY to specifications",
      "Delete specs after implementation",
      "Extract specs from code",
      "Use context as spec"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Spec Driven Development",
      "subtitle": "Specs Are Scaffolding, Not Architecture",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "DRY and Single Source of Truth aren't methodology buzzwords—they're sanity-preserving engineering practices. When the same information exists in multiple places, it drifts. Your codebase is a knowledge base. Every function, test, and constraint encodes knowledge. Spec Driven Development is a technique for adding or modifying knowledge while respecting these principles.",
        "timing": "1 minute",
        "discussion": "How many of you have encountered a spec that contradicts the actual code? What happened?",
        "context": "This lesson builds on Lesson 11's agent-friendly code and Lesson 5's grounding tools. It reframes specs as temporary artifacts, not permanent documentation.",
        "transition": "Let's start by understanding how knowledge expands during development."
      }
    },
    {
      "type": "visual",
      "title": "The SDLC Knowledge Expansion",
      "component": "KnowledgeExpansionDiamond",
      "caption": "Each development phase expands the knowledge from the phase above.",
      "speakerNotes": {
        "talkingPoints": "Traditional software development follows a pattern of knowledge expansion. The high-level spec captures the 'what' and 'why.' The detailed design explores the 'how'—edge cases, constraints, error handling, data flows. The code encodes implementation details, performance optimizations, and the full refined understanding. With AI agents, this happens in hours rather than weeks, but the expansion pattern remains the same.",
        "timing": "2-3 minutes",
        "discussion": "Think about a recent feature you built. Can you trace the knowledge expansion from initial requirement to final code?",
        "context": "This mirrors traditional waterfall but compressed. The key insight is that each layer is a knowledge expansion of the layer above—not a separate artifact.",
        "transition": "Once implementation is complete, we face a critical problem."
      }
    },
    {
      "type": "concept",
      "title": "The Duplicate Knowledge Problem",
      "content": [
        "After implementation: spec + design + code",
        "Three sources = three different truths",
        "Stale specs mislead future agents",
        "Knowledge Cache Anti-Pattern from Lesson 11"
      ],
      "speakerNotes": {
        "talkingPoints": "Once implementation is complete and the code passes tests and review, the same knowledge exists in three places. The spec says 'users can have at most 5 active sessions.' The code implements a limit of 10. The design document mentions 'configurable session limits.' Three sources, three different truths. This is exactly the Knowledge Cache Anti-Pattern from Lesson 11—saved specifications become stale the moment code changes.",
        "timing": "2-3 minutes",
        "discussion": "Has anyone found a design doc that said one thing while the code did something completely different? What was the impact?",
        "context": "Future agents researching your codebase find both the outdated spec and the current code, leading to confusion and conflicting implementations.",
        "transition": "So what's the solution? Understanding which spec knowledge matters."
      }
    },
    {
      "type": "comparison",
      "title": "HOW Knowledge vs WHY Knowledge",
      "neutral": true,
      "left": {
        "label": "HOW Knowledge (Delete)",
        "content": [
          "Implementation details and data flows",
          "Edge cases and error handling",
          "Fully encoded in code after implementation",
          "Redundant once code exists"
        ]
      },
      "right": {
        "label": "WHY Knowledge (Preserve)",
        "content": [
          "Rejected alternatives and trade-offs",
          "Business rationale for constraints",
          "Compliance mandates and context",
          "Residual that doesn't migrate to code"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Not all spec knowledge is equal. HOW knowledge—implementation details, data flows, edge cases—gets fully encoded in code during implementation. Once the code exists, the spec's HOW is redundant. WHY knowledge—rejected alternatives, business rationale, compliance mandates—can't be expressed in code. A constraint comment tells the agent what to enforce, but not why you chose idempotency-via-database over idempotency-via-cache. That rationale is the residual.",
        "timing": "3-4 minutes",
        "discussion": "Think of a constraint in your codebase. Can you articulate WHY it exists, or only WHAT it enforces?",
        "context": "The solution: delete the HOW spec after implementation. The code is the single source of truth. For the small WHY residual, have the agent diff the original spec against the final code—the residual gets committed as a decision record from Lesson 11.",
        "transition": "This is where our approach diverges from mainstream SDD tools."
      }
    },
    {
      "type": "comparison",
      "title": "Mainstream SDD vs This Approach",
      "left": {
        "label": "Living Spec Model",
        "content": [
          "Specs as permanent living artifacts",
          "Bidirectional spec-code sync assumed",
          "Two sources of truth for same knowledge",
          "Developers modify code, spec drifts"
        ]
      },
      "right": {
        "label": "Ephemeral Spec Model",
        "content": [
          "Code is the source of truth—period",
          "Specs are temporary scaffolding",
          "Delete specs after implementation",
          "Regenerate on-demand from code"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Tools like GitHub Spec Kit, Amazon Kiro, and Tessl treat specifications as permanent living artifacts that evolve alongside code. This violates single source of truth. The moment you have two representations of the same knowledge, you have a consistency problem. This isn't new—it's why we eliminated header files where possible, why we generate API docs from code, why we generate OpenAPI specs from code annotations. The living spec model assumes perfect bidirectional sync that never works in practice.",
        "timing": "3-4 minutes",
        "discussion": "How many tools or workflows in your organization maintain a 'living spec'? How well does the sync actually work?",
        "context": "The correct approach: code is the source of truth. Specs are temporary scaffolding for the creation process. Delete them after implementation and regenerate on-demand from code when needed.",
        "transition": "The key enabler is that grounding tools are actually knowledge extraction engines."
      }
    },
    {
      "type": "concept",
      "title": "Code as Compression Source",
      "content": [
        "Grounding tools extract knowledge dynamically",
        "Same code compresses to different shapes",
        "No stale caches, no conflicting sources",
        "Knowledge extraction replaces static docs"
      ],
      "speakerNotes": {
        "talkingPoints": "Agentic search, semantic search, code research tools—these aren't just discovery tools. They're knowledge extraction and compression engines. The same 50,000 tokens of code can be compressed into different shapes depending on what you ask: 'What does this module do?' yields a high-level spec. 'How is authentication implemented?' yields detailed design. 'What's the API contract?' yields interface documentation. Same source of truth, different compression targets.",
        "timing": "2-3 minutes",
        "discussion": "When was the last time you needed to understand a module? Did you read a doc or read the code? Which was more accurate?",
        "context": "This connects to Lesson 5's grounding tools. When ChunkHound's code research processes 50,000 tokens of raw code and returns a 3,000-token synthesis, that synthesis IS a spec—extracted on-demand from the source of truth.",
        "transition": "Now let's apply this to the practical workflow of modifying existing code."
      }
    },
    {
      "type": "codeExecution",
      "title": "Modifying Existing Code: The Workflow",
      "steps": [
        {
          "line": "1. Extract spec from code via grounding tools",
          "highlightType": "execution",
          "annotation": "Surface current implementation as a spec shaped for your audience"
        },
        {
          "line": "Product → behavioral specs: what users can do",
          "highlightType": "feedback",
          "annotation": "'Users can have up to 5 concurrent sessions'"
        },
        {
          "line": "Engineers → systems specs: how components interact",
          "highlightType": "feedback",
          "annotation": "'SessionManager enforces MAX_SESSIONS=5 via Redis sorted set'"
        },
        {
          "line": "QA → constraint specs: boundaries and edge cases",
          "highlightType": "feedback",
          "annotation": "'Boundary: exactly 5 sessions. Edge: 6th login evicts oldest'"
        },
        {
          "line": "2. Modify the spec with desired changes",
          "highlightType": "human",
          "annotation": "Edit the extracted spec to reflect new requirements"
        },
        {
          "line": "3. Gap-analyze: spec vs current implementation",
          "highlightType": "prediction",
          "annotation": "What exists? What's missing? What conflicts?"
        },
        {
          "line": "4. Research → Plan → Execute → Validate",
          "highlightType": "execution",
          "annotation": "Standard four-phase workflow from modified spec"
        },
        {
          "line": "5. Delete temporary spec files and scaffolding",
          "highlightType": "summary",
          "annotation": "Code is the source of truth again"
        }
      ],
      "speakerNotes": {
        "talkingPoints": "When modifying existing code, knowledge already lives in the implementation. Extract it, reshape it for whoever needs to approve or understand the change, modify it, then re-implement. The shape of the extracted spec depends on your audience—product stakeholders need behavioral specs, engineers need systems specs, QA needs constraint specs. Same source code, different compression targets.",
        "timing": "3-4 minutes",
        "discussion": "Who are the different audiences for spec extractions in your organization? What shapes do they need?",
        "context": "This is the practical application: extract → modify → gap-analyze → implement → delete. The gap analysis bridges 'where we are' to 'where we want to be.'",
        "transition": "Here's a realization that might surprise you—you've been doing SDD all along."
      }
    },
    {
      "type": "concept",
      "title": "The Context Window as Working Spec",
      "content": [
        "Every grounding session extracts a spec",
        "Every prompt describes requirements (updates spec)",
        "Implementation runs from those requirements",
        "Closing the conversation deletes the spec"
      ],
      "speakerNotes": {
        "talkingPoints": "If you've followed this course, you've been practicing SDD all along. Every time you grounded in the codebase before modifying it—that's extracting the spec. Every time you described requirements in your prompt—that's updating the spec. Every time the agent implemented from those requirements—that's coding from spec. Every time you closed the conversation—the spec served its purpose. The spec lived in your context window—RAM, not disk.",
        "timing": "2-3 minutes",
        "discussion": "Does this reframe how you think about your prompting workflow? What changes?",
        "context": "What makes this safe is constraint migration: during implementation, the agent inlines spec constraints—with their IDs—into code comments. The WHY moves from spec to code. When you close the conversation, nothing is lost.",
        "transition": "But not every task fits in a single session."
      }
    },
    {
      "type": "comparison",
      "title": "When to Persist Specs",
      "neutral": true,
      "left": {
        "label": "Persist Specs",
        "content": [
          "Work spans multiple days or sessions",
          "Scope exceeds ~100k token context",
          "Multiple agents or people coordinate",
          "Architectural decisions need maturation"
        ]
      },
      "right": {
        "label": "Keep Specs Ephemeral",
        "content": [
          "Task completes in one session",
          "Iterating quickly (hours, not days)",
          "Scope fits comfortably in context",
          "Single agent, single developer"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "For single-session tasks, the context window is your spec file. But larger tasks need coordination across sessions. Persist specs when work spans multiple days, scope exceeds comfortable context limits, multiple agents or people need to coordinate, or architectural decisions need time to mature. Keep specs ephemeral when the task completes in one session and you're iterating quickly.",
        "timing": "2-3 minutes",
        "discussion": "Think about your current project. Which tasks would benefit from persisted specs vs ephemeral ones?",
        "context": "Remember: specs are scaffolding, not architecture. Even when you persist them, they should be deleted after implementation completes.",
        "transition": "Let's wrap up with the key takeaways from this lesson."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways",
      "content": [
        "Code is the knowledge base",
        "Delete specs after implementation",
        "Extract, modify, implement, delete",
        "Regenerate specs on demand"
      ],
      "speakerNotes": {
        "talkingPoints": "Four critical insights: First, your codebase is a knowledge base—every line encodes requirements, constraints, and decisions. Second, specs have a lifecycle—they're scaffolding, not permanent artifacts. Delete them after implementation. Third, the modification workflow is extract → modify → implement → delete. Fourth, grounding tools are knowledge extraction engines—regenerate specs on-demand instead of maintaining static documentation.",
        "timing": "2 minutes",
        "discussion": "What's one thing from this lesson that changes how you'll approach your next feature? Will you think differently about maintaining spec documents?",
        "context": "This lesson fundamentally challenges the 'living spec' model popular in current tooling. The next lesson (Lesson 13) will build on these ideas with systems thinking and iterative spec-code convergence.",
        "transition": "In Lesson 13, we'll explore how specs and code converge iteratively in complex systems."
      }
    }
  ]
}