{
  "metadata": {
    "title": "Debugging with AI Agents",
    "lessonId": "lesson-10-debugging",
    "estimatedDuration": "40-50 minutes",
    "learningObjectives": [
      "Demand reproducible proof for fixes",
      "Leverage AI for log pattern analysis",
      "Build closed-loop debugging workflows",
      "Use diagnostic scripts for remote issues"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Debugging with AI Agents",
      "subtitle": "Evidence, not speculation—prove every fix works",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "This lesson is about fundamentally changing how you debug when AI agents are involved. Traditional debugging often relies on description and hope—you describe a symptom, and the agent guesses what's wrong. Production debugging with AI requires evidence at every step: reproducible proof the bug exists, then verified proof the fix works.",
        "timing": "1 minute",
        "discussion": "Ask students: 'How many debugging cycles do you typically go through before a fix actually works in production?' This lesson will teach you to reduce that to 1-2 cycles.",
        "context": "In production systems, speculation is expensive. Each iteration cycle can take hours—waiting for CI, deployment, observing the fix, reporting back. AI agents excel when constrained to evidence-driven workflows.",
        "transition": "Let's start with the core principle that changes everything about debugging with AI."
      }
    },
    {
      "type": "concept",
      "title": "The Debugging Shift: Evidence Over Speculation",
      "content": [
        "Describe symptoms → Agent guesses blindly",
        "Provide reproduction steps → Agent investigates systematically",
        "Require before/after evidence → Verify fix actually works",
        "AI agents excel at pattern recognition with concrete data",
        "Move from 'what do you think?' to 'prove it works'"
      ],
      "speakerNotes": {
        "talkingPoints": "The fundamental shift is this: traditional debugging is speculative. You tell the agent 'it's returning a 500 error' and it suggests a fix. With evidence-driven debugging, you provide the agent reproduction steps, logs, and the actual error output. The agent then must validate its hypothesis against concrete data. This transforms debugging from guessing to investigation.",
        "timing": "3-4 minutes",
        "discussion": "Have students think about a recent bug they debugged. Did they describe the symptom or provide reproduction steps? What difference would reproducible steps have made?",
        "context": "Anti-pattern: 'Agent, there's a bug in the authentication flow. Can you fix it?' Production pattern: 'Here are steps to reproduce: 1) POST /auth 2) Include malformed JWT 3) Observe 500 instead of 401. Explain what's happening, then fix it and verify with reproduction.'",
        "transition": "Before jumping to fixes, you need to understand the system. Let's talk about code inspection."
      }
    },
    {
      "type": "concept",
      "title": "Code Inspection: Understanding Before Fixing",
      "content": [
        "Trace request paths and execution flow before diving into fixes",
        "Use semantic code search to find relevant components",
        "Ask agent to identify potential failure points",
        "Explain architecture mismatches between your model and reality",
        "Edge cases and assumptions reveal themselves during tracing"
      ],
      "speakerNotes": {
        "talkingPoints": "Many engineers jump straight to logs when a bug appears. Before that, have the agent trace the code path. Ask it to explain how an API request flows through your system—through middleware, through service layers, down to database queries. This explanation often reveals edge cases you missed. For example: 'Trace authentication from request header through JWT validation to token refresh. Where could a race condition occur?' The agent's explanation of the actual code path often surfaces the real problem before you even look at logs.",
        "timing": "3-4 minutes",
        "discussion": "Ask: 'When was the last time understanding the code path actually changed what you thought the bug was?' Most developers skip this step.",
        "context": "In monolithic systems, tracing is straightforward. In microservices with 5+ layers, tracing is critical—the agent can quickly explain service boundaries and potential timing issues.",
        "transition": "Once you understand the code, logs become the detective work. This is where AI truly shines."
      }
    },
    {
      "type": "comparison",
      "title": "Log Analysis: Human vs AI Capabilities",
      "left": {
        "label": "Human Analysis",
        "content": [
          "Manually scroll through thousands of entries",
          "Search by keyword or timestamp",
          "Spot one error, miss cascading failures",
          "Inconsistent formats from different services overwhelm",
          "Correlation across logs takes days"
        ]
      },
      "right": {
        "label": "AI Pattern Recognition",
        "content": [
          "Process entire log streams in context",
          "Spot patterns across formats and services",
          "Identify cascading errors and timing issues",
          "Extract structured data from raw output",
          "Correlate distributed traces instantly"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "This is where AI has the biggest advantage in debugging. Multi-line stack traces, logs from 5 different services with different formats, verbose debug output—humans struggle with this chaos. AI processes it instantly. The messier your logs, the bigger AI's advantage.",
        "timing": "2-3 minutes",
        "discussion": "Have someone share their worst log debugging story. AI would have solved it in minutes.",
        "context": "Examples: AI spots cascading errors in microservices with different logging styles, identifies timing patterns indicating race conditions buried in verbose output, pinpoints specific user cohorts experiencing failures across fragmented logs.",
        "transition": "Now, how do you give the agent logs to analyze?"
      }
    },
    {
      "type": "concept",
      "title": "Feeding Logs to AI Agents",
      "content": [
        "Paste grep output directly—AI doesn't need perfect JSON",
        "Pipe raw debug output, uploaded files, or CLI access work equally",
        "Structured logs (timestamps, request IDs, JSON) help both human and AI",
        "Add targeted diagnostic statements preemptively during investigation",
        "Fifteen minutes of logging beats hours of speculation"
      ],
      "speakerNotes": {
        "talkingPoints": "Don't wait for perfect logging infrastructure. AI works with what you have—raw output, inconsistent formats, whatever. But here's the power move: once the agent forms a hypothesis, ask it to suggest specific log statements to add. Instead of blindly adding logs everywhere, you add targeted diagnostics at strategic points. The agent analyzes the new output immediately. This transforms instrumentation from 'add logs globally' to 'add evidence for this specific hypothesis.'",
        "timing": "2-3 minutes",
        "discussion": "Ask: 'How many logging statements do you add in a typical debugging session?' The answer is usually 'not nearly enough.' With AI guidance, you can instrument 20+ strategic points in minutes.",
        "context": "Production insight: What would be prohibitively tedious for humans (add logs at dozens of points, analyze output, remove logs) becomes routine with AI. You shift from minimal instrumentation to evidence-rich exploration. Once the bug is fixed, the same agent removes all diagnostic statements, maintaining code hygiene.",
        "transition": "Sometimes logs and code inspection aren't enough. You need to actually reproduce the bug."
      }
    },
    {
      "type": "concept",
      "title": "Reproduction Scripts: Code is Cheap",
      "content": [
        "AI generates Docker configs, database snapshots, mock services trivially",
        "What takes humans hours takes agents minutes to scaffold",
        "Captures full context: state, API responses, config, user inputs",
        "Reliable reproduction eliminates ambiguity",
        "Agent can iterate on fixes and verify each attempt systematically"
      ],
      "speakerNotes": {
        "talkingPoints": "When you need bulletproof evidence or must reproduce complex state/timing conditions, reproduction scripts are invaluable. Here's the shift: instead of spending a day manually setting up a test environment, ask the agent to generate it. 'Create a Docker environment with: PostgreSQL snapshot from production state, mock OAuth service, API calls that trigger the bug reliably.' The agent generates this in minutes. Code generation is cheap.",
        "timing": "3-4 minutes",
        "discussion": "Ask for a show of hands: 'How many of you have spent a day trying to reproduce a bug locally?' This is where AI saves enormous time.",
        "context": "Example: A customer reports a race condition in order processing. Reproducing locally requires: database schema, specific order state, concurrent requests at precise timing. The agent generates a Docker Compose setup with database initialization, concurrent request script, and timing hooks—all in one prompt.",
        "transition": "Once you have reproduction, you can place the agent inside the failing environment. This is where the real power emerges."
      }
    },
    {
      "type": "codeExecution",
      "title": "Closed-Loop Debugging Workflow",
      "steps": [
        {
          "line": "Engineer specifies: 'Authentication returning 500 when JWT invalid'",
          "highlightType": "human",
          "annotation": "Problem statement with context"
        },
        {
          "line": "Agent creates: Docker container, test database, reproduction script",
          "highlightType": "execution",
          "annotation": "BUILD phase—create reproducible environment"
        },
        {
          "line": "Script executes: invalid JWT request → observe 500 response",
          "highlightType": "execution",
          "annotation": "REPRODUCE phase—verify bug manifests consistently"
        },
        {
          "line": "Agent reads code: jwt.ts, auth middleware, error handlers",
          "highlightType": "execution",
          "annotation": "PLACE—agent has code and environment access"
        },
        {
          "line": "Agent hypothesizes: 'Missing algorithm validation in RS256'",
          "highlightType": "prediction",
          "annotation": "INVESTIGATE—form hypothesis from evidence"
        },
        {
          "line": "Agent edits: jwt.ts:67, adds algorithm check",
          "highlightType": "execution",
          "annotation": "Apply the fix"
        },
        {
          "line": "Reproduction script re-runs: returns 401 (correct)",
          "highlightType": "feedback",
          "annotation": "VERIFY—prove fix works with concrete evidence"
        },
        {
          "line": "Agent reports: 'Fixed and verified. RS256 validation at jwt.ts:67.'",
          "highlightType": "prediction",
          "annotation": "Closed loop—problem solved with proof"
        }
      ],
      "speakerNotes": {
        "talkingPoints": "This is the complete debugging cycle with AI. Notice the difference from open-loop: you're not just reading code and guessing. You're building an environment where the agent can actually test its hypotheses. BUILD creates reproducibility. REPRODUCE verifies the problem exists. PLACE gives the agent access. INVESTIGATE combines code analysis with empirical testing. VERIFY proves the fix works. The entire loop is closed—the agent's reasoning is validated or refuted by the environment.",
        "timing": "4-5 minutes",
        "discussion": "Ask: 'In your last debugging session, how many times did a proposed fix not actually work?' This workflow prevents that waste.",
        "context": "The key shift: without environment access, an agent proposes solutions it can't validate. With closed-loop access, it applies fixes, re-runs reproduction, and proves they work—or forms new hypotheses when they don't.",
        "transition": "This workflow requires one critical capability: the agent must be able to execute code and commands in your environment."
      }
    },
    {
      "type": "comparison",
      "title": "IDE Agents vs CLI Agents for Debugging",
      "left": {
        "label": "IDE Agents (Limited)",
        "content": [
          "Tied to your local development machine",
          "Can read code, edit code, run local tests",
          "Can't access Docker containers directly",
          "Can't connect to remote services",
          "No CI/CD or production environment access"
        ]
      },
      "right": {
        "label": "CLI Agents (Flexible)",
        "content": [
          "Work anywhere you have shell access",
          "Inside Docker containers for isolated testing",
          "On remote servers and production instances",
          "Integrated into CI/CD pipelines",
          "Can execute commands, inspect processes, access logs"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Here's a critical insight: IDE agents (like Copilot in VS Code) are tied to your local machine. CLI agents (Claude Code, Terminal access) can run anywhere. For debugging, this matters enormously. You can't reproduce a production race condition on your laptop. But a CLI agent can spin up a Docker environment, run concurrent requests, and verify fixes in a way an IDE agent cannot.",
        "timing": "3-4 minutes",
        "discussion": "Ask: 'When was the last time the bug you were debugging only happened on someone else's machine?' That's when you need a CLI agent that can access their environment.",
        "context": "Example: A bug only appears under load. The IDE agent can read the code but can't run load tests against a distributed system. The CLI agent can execute load testing tools, monitor responses, and collect evidence.",
        "transition": "Now, what if you can't access the failing environment directly?"
      }
    },
    {
      "type": "concept",
      "title": "Remote Diagnosis: When Access is Limited",
      "content": [
        "Generate ranked hypotheses from code and known issues",
        "Create targeted diagnostic scripts to test each hypothesis",
        "Trade developer time for compute time—scripts are cheap",
        "Collect evidence for customer deployments or edge infrastructure",
        "Correlate script output with hypotheses to identify root cause"
      ],
      "speakerNotes": {
        "talkingPoints": "Sometimes you can't access the failing environment. Customer deployments, locked-down production, edge infrastructure—you have limited information and can't iterate. This is where AI's probabilistic reasoning becomes a feature. Instead of guessing, you generate ranked hypotheses based on evidence from code analysis and known issues. Then you generate targeted diagnostic scripts that test each hypothesis. The customer runs the script and sends the output. You load that output into the agent's context, and it correlates evidence with hypotheses. What would take humans days takes agents 30 minutes to script, and humans to analyze the results.",
        "timing": "3-4 minutes",
        "discussion": "Ask: 'How many times have you asked a customer for 'more detailed logs' without knowing what to look for?' This approach tells you exactly what to ask for.",
        "context": "Example: Customer reports intermittent 504 errors. You generate a script that checks: service version, configuration mismatches with documentation, network connectivity, database connection pool exhaustion, memory usage patterns. The script outputs structured data. The agent analyzes it and identifies: database pool misconfigured, causing 504s under load. Diagnosis complete in one cycle.",
        "transition": "Let's wrap up with the key insights you should take away."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways: Debugging with AI",
      "content": [
        "Evidence over speculation—never accept fixes without reproducible proof",
        "Closed-loop debugging with agents: BUILD → REPRODUCE → PLACE → INVESTIGATE → VERIFY",
        "AI's real power in debugging is pattern recognition across messy logs and fast code generation",
        "Use CLI agents for environment access; reproduction scripts are your debugging infrastructure"
      ],
      "speakerNotes": {
        "talkingPoints": "These four insights transform debugging from a frustrating guessing game into a systematic, evidence-driven process. The old pattern was: agent guesses, you test, fix fails, repeat 5+ times. The new pattern: you build reproducibility, place the agent in the environment, and it iterates itself—verify first, deploy once. The shift from speculation to evidence is the entire lesson.",
        "timing": "2-3 minutes",
        "discussion": "Ask students: 'What's one change you'll make to your next debugging session based on this lesson?' Have them commit to it.",
        "context": "The production reality: these techniques cut debugging time from days to hours, and more importantly, reduce the risk of shipping broken fixes. Evidence-driven debugging is more rigorous than guessing.",
        "transition": "That's debugging with AI agents. The principle is simple: require proof at every step."
      }
    }
  ]
}
