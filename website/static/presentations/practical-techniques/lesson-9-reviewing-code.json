{
  "metadata": {
    "title": "Reviewing Code with AI",
    "lessonId": "lesson-9-reviewing-code",
    "estimatedDuration": "35-45 minutes",
    "learningObjectives": [
      "Review in fresh context",
      "Iterate until green light",
      "Generate dual-optimized PR descriptions",
      "Leverage AI for PR reviews"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Reviewing Code with AI",
      "subtitle": "The Validate Phase: Systematic Quality Gates",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "This lesson covers the Validate phase from Lesson 3's four-phase workflow. After implementation and tests pass, code review is the critical quality gate that catches probabilistic errors agents inevitably introduce—subtle logic bugs, architectural mismatches, edge cases handled incorrectly, patterns that don't fit your codebase.",
        "timing": "1 minute",
        "discussion": "Ask students: How many have shipped AI-generated code that passed tests but had subtle logic bugs discovered later?",
        "context": "This lesson assumes familiarity with the four-phase workflow (Research, Plan, Execute, Validate) from Lesson 3 and test-driven development from Lesson 8.",
        "transition": "Let's start by understanding the critical insight that makes AI code review effective..."
      }
    },
    {
      "type": "concept",
      "title": "The Fresh Context Principle",
      "content": [
        "Review in fresh context, separate from implementation",
        "Prevents confirmation bias—agents defend their own decisions",
        "Leverages stateless nature of LLMs (Lessons 1-2)",
        "Agent reviewing its own work in same conversation is ineffective"
      ],
      "speakerNotes": {
        "talkingPoints": "The key insight: review in a fresh context, separate from where the code was written. An agent reviewing its own work in the same conversation will defend its decisions because the conversation history contains the reasoning that led to those choices. An agent in a fresh context analyzes objectively, without attachment to prior decisions. This leverages the stateless nature of LLMs we covered in Lessons 1 and 2.",
        "timing": "3 minutes",
        "discussion": "Ask: Have you noticed LLMs defending their own suggestions when you question them in the same conversation? What happened when you started a new conversation?",
        "context": "In production, this means: git diff the changes, start a new agent conversation, and feed the diff for review. Never ask the agent that wrote the code to review it in the same session.",
        "transition": "Now let's look at the structured review prompt template that implements these principles..."
      }
    },
    {
      "type": "code",
      "title": "Review Prompt Template",
      "language": "markdown",
      "code": "You are an expert code reviewer. Analyze the current changeset and provide a critical review.\n\nThe changes in the working tree were meant to: $DESCRIBE_CHANGES\n\nThink step-by-step through each aspect below, focusing solely on the changes in the working tree.\n\n1. **Architecture & Design**\n   - Verify conformance to project architecture\n   - Check module responsibilities are respected\n   - Ensure changes align with the original intent\n\n2. **Code Quality**\n   - Code must be self-explanatory and readable\n   - Style must match surrounding code patterns\n   - Changes must be minimal - nothing unneeded\n   - Follow KISS principle\n\n3. **Maintainability**\n   - Optimize for future LLM agents working on the codebase\n   - Ensure intent is clear and unambiguous\n   - Verify comments and docs remain in sync with code\n\n4. **User Experience**\n   - Identify areas where extra effort would significantly improve UX\n   - Balance simplicity with meaningful enhancements\n\nReview the changes critically. Focus on issues that matter.\nUse ChunkHound's code research.\nDO NOT EDIT ANYTHING - only review.",
      "caption": "Integrates techniques from Lesson 4: persona, CoT, structure, grounding, constraints",
      "speakerNotes": {
        "talkingPoints": "This template integrates multiple techniques from Lesson 4 (Prompting 101). Notice the persona ('expert code reviewer'), chain-of-thought structure (numbered steps), grounding requirements ('use ChunkHound'), and explicit constraints ('DO NOT EDIT'). Each element serves a purpose—the persona sets behavioral expectations, CoT forces systematic analysis, grounding prevents hallucinations, constraints prevent the agent from 'fixing' issues instead of reporting them.",
        "timing": "4-5 minutes",
        "discussion": "Ask students to identify which Lesson 4 techniques they see in this template. What would happen if we removed the 'DO NOT EDIT' constraint?",
        "context": "In production, you'd adapt this template for different review types: security audits (focus on OWASP top 10), performance analysis (focus on algorithmic complexity), architectural review (focus on module boundaries). The structure remains the same—only the numbered sections change.",
        "transition": "This template gives us a starting point, but review is rarely one-pass. Let's look at the iterative cycle..."
      }
    },
    {
      "type": "concept",
      "title": "Iterative Review Until Green or Diminishing Returns",
      "content": [
        "Review → Fix → Re-run tests → Review in FRESH context",
        "Review itself is probabilistic—LLM can suggest bad 'fixes'",
        "Stop at green light (tests pass, no substantive issues)",
        "Stop at diminishing returns (nitpicking, hallucinations, review-induced failures)"
      ],
      "speakerNotes": {
        "talkingPoints": "Code review is rarely one-pass. First review finds issues, you fix them, re-run tests (Lesson 8) to catch regressions, then review AGAIN in a fresh context—not the same conversation where the agent will defend its prior decisions. Review itself is probabilistic—it's also an LLM making statistical predictions. The agent can be wrong about what needs fixing, and its 'fixes' might break working code. Your test suite catches these regressions.",
        "timing": "4 minutes",
        "discussion": "Ask: How do you know when to stop iterating? What signals indicate diminishing returns?",
        "context": "In production, diminishing returns manifest as: nitpicking (trivial style preferences), hallucinations (inventing non-existent issues), review-induced test failures (the 'fix' broke working code), or excessive cost (4+ iterations for minor issues). At that point, trust your tests as the objective arbiter and ship the code.",
        "transition": "We've covered reviewing your own code. Now let's look at how to structure PRs so others can review effectively with AI assistance..."
      }
    },
    {
      "type": "concept",
      "title": "PRs Serve Two Audiences",
      "content": [
        "Humans: scan quickly, infer context, value concise summaries (1-3 paragraphs)",
        "AI assistants: parse chunk-by-chunk, need explicit structure and detailed context",
        "Traditional PRs optimize for one audience, sacrificing the other",
        "Solution: Generate dual-optimized descriptions in coordinated workflow"
      ],
      "speakerNotes": {
        "talkingPoints": "Pull requests serve two audiences: human maintainers and their AI review assistants. These audiences process information fundamentally differently. Humans scan quickly, infer meaning from context, and value concise summaries. AI assistants parse content chunk-by-chunk, struggle with vague pronouns, and need explicit structure (Lesson 5 grounding principles). Traditional PR descriptions optimize for one audience or the other—too verbose for humans, too vague for AI agents.",
        "timing": "3 minutes",
        "discussion": "Ask: Have you tried using AI to review a PR with a vague description? What happened? What about PRs with comprehensive but verbose descriptions—did you read all of it?",
        "context": "In production, the solution is to generate both descriptions in a coordinated workflow using sub-agents. Human-optimized goes in the GitHub PR description (visible immediately). AI-optimized goes in a separate markdown file (PR_REVIEW_CONTEXT.md) that reviewers feed to their AI assistants.",
        "transition": "Let's look at the advanced prompt pattern that generates both descriptions..."
      }
    },
    {
      "type": "code",
      "title": "Dual-Optimized PR Generation Prompt",
      "language": "markdown",
      "code": "You are a contributor to {PROJECT_NAME} creating a GitHub pull request for the current branch.\nUsing the sub task tool to conserve context, explore the changes in the git history relative to main.\nSummarize and explain them like you would to a fellow co-worker:\n\n- Direct and concise\n- Professional but conversational\n- Assume competence and intelligence\n- Skip obvious explanations\n\nThe intent of the changes are:\n{CHANGES_DESC}\n\nBuilding upon this, draft two markdown files: one for a human reviewer/maintainer of the project\nand another complementary that's optimized for the reviewer's agent. Explain:\n\n- What was done and the reasoning behind it\n- Breaking changes, if any exist\n- What value the changes adds to the project\n\nConstraints:\n\n- The human optimized markdown file should be 1-3 paragraphs max\n- Agent optimized markdown should focus on explaining the changes efficiently\n\nUse ArguSeek, learn how to explain and optimize both for humans and LLMs.\nUse the code research to learn the overall architecture, module responsibilities and coding style.",
      "caption": "Combines Lesson 5 (grounding), Lesson 4 (structured prompts), Lesson 7 (sub-agents for context conservation)",
      "speakerNotes": {
        "talkingPoints": "This prompt demonstrates multiple advanced techniques. 'Using the sub task tool to conserve context' spawns a separate agent for git history exploration, preventing the main orchestrator's context from filling with commit diffs (Lesson 5 context conservation). ArguSeek grounds in PR best practices while ChunkHound grounds in your actual codebase. The structured format ('draft two markdown files') and constraints ('1-3 paragraphs max') direct the agent to produce dual-optimized outputs (Lesson 4 structured prompting).",
        "timing": "5 minutes",
        "discussion": "Ask: Why spawn a sub-agent for git history exploration instead of doing it in the main prompt? What would happen to context consumption? (Answer: exploring 20-30 changed files consumes 40K+ tokens, pushing critical constraints into the U-shaped attention curve's ignored middle.)",
        "context": "This sub-agent capability is unique to Claude Code CLI. Other tools (Codex, GitHub Copilot) require splitting this into multiple sequential prompts: explore first, then draft based on findings. The efficiency gain is significant—you get both descriptions in one workflow.",
        "transition": "Now let's flip perspectives—you're reviewing someone else's PR that has dual-optimized descriptions..."
      }
    },
    {
      "type": "concept",
      "title": "Consuming Dual PR Descriptions as Reviewer",
      "content": [
        "Human-optimized (PR description): Read first for 'why' and business value",
        "AI-optimized (PR_REVIEW_CONTEXT.md): Feed to your AI assistant for technical analysis",
        "Human description forms your mental model quickly",
        "AI description provides grounding and context for accurate AI-assisted review"
      ],
      "speakerNotes": {
        "talkingPoints": "When you're on the receiving end of a PR with dual-optimized descriptions, consume them strategically. Read the human-optimized description first (GitHub PR description) to understand the 'why' and business value—this forms your mental model quickly. Then feed the AI-optimized description to your AI review assistant. This provides the comprehensive technical context the AI needs for accurate analysis—explicit terminology, file paths, architectural patterns—reducing hallucinations and improving review quality.",
        "timing": "3 minutes",
        "discussion": "Ask: What's your current workflow for reviewing PRs? Do you feed PR descriptions to AI assistants? What happens when the description is vague?",
        "context": "In production, this separation of concerns is efficient. You spend 2 minutes reading the human description, form a mental model, then let your AI assistant do the deep technical analysis grounded in the AI-optimized context. You focus on architectural decisions and business logic; the AI catches implementation details, edge cases, and consistency issues.",
        "transition": "Let's look at the review prompt pattern you'd use with your AI assistant..."
      }
    },
    {
      "type": "code",
      "title": "AI-Assisted PR Review Prompt",
      "language": "markdown",
      "code": "You are {PROJECT_NAME}'s maintainer reviewing {PR_LINK}. Ensure code quality, prevent technical debt, and maintain architectural consistency.\n\nContext from the PR author:\n{PASTE_AI_OPTIMIZED_DESCRIPTION}\n\n# Review Process\n\n1. Use GitHub CLI to read the PR discussions, comments, and related issues\n2. Think step by step, but only keep a minimum draft for each thinking step, with 5 words at most. End the assessment with a separator ####.\n3. Never speculate about code you haven't read - investigate files before commenting\n\n# Critical Checks\n\nBefore approving, verify:\n\n- Can existing code be extended instead of creating new?\n- Does this respect module boundaries and responsibilities?\n- Are there similar patterns elsewhere? Search the codebase.\n- Is this introducing duplication?\n\n# Output Format\n\n```markdown\n**Summary**: [One sentence verdict]\n**Strengths**: [2-3 items]\n**Issues**: [By severity: Critical/Major/Minor with file:line refs]\n**Reusability**: [Specific refactoring opportunities]\n**Decision**: [APPROVE/REQUEST CHANGES/REJECT]\n```\n\nStart by executing `gh pr view {PR_LINK} --comments`, follow with the Code Research tool for codebase understanding.",
      "caption": "Notice Review Process step 2: Chain of Draft (CoD)—efficient alternative to Chain of Thought",
      "speakerNotes": {
        "talkingPoints": "This prompt integrates the AI-optimized context from the PR author and adds critical checks focused on preventing duplication and technical debt. Notice Review Process step 2: 'Think step by step, but only keep a minimum draft for each thinking step, with 5 words at most.' This is Chain of Draft (CoD)—an optimization of Chain of Thought that maintains structured reasoning while reducing token consumption. The agent thinks through each step but keeps drafts concise, then returns the final assessment after a separator. Same reasoning benefits as CoT, but faster and cheaper.",
        "timing": "4 minutes",
        "discussion": "Ask: What's the difference between Chain of Thought and Chain of Draft? When would you use each? (Answer: CoT for complex reasoning where you need visibility into each step; CoD for systematic analysis where the final assessment is what matters.)",
        "context": "In production, this review pattern catches issues your manual review might miss: code duplication across modules, architectural boundary violations, patterns that exist elsewhere in the codebase. The AI assistant has perfect recall of the entire codebase—you don't. The 'never speculate' constraint forces evidence-based review (Lesson 7).",
        "transition": "Let's summarize the key takeaways from this lesson..."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways",
      "content": [
        "Review in fresh context",
        "Iterate until green light",
        "Generate dual-optimized PR descriptions",
        "Chain of Draft optimizes reviews"
      ],
      "speakerNotes": {
        "talkingPoints": "Four critical takeaways: (1) Review in fresh context to prevent confirmation bias—an agent reviewing its own work will defend its decisions. (2) Iterate the review cycle (review, fix, test, re-review) until you reach a green light or diminishing returns. (3) Generate dual-optimized PR descriptions—humans need concise summaries, AI assistants need comprehensive technical context. (4) Chain of Draft provides the same reasoning benefits as Chain of Thought with reduced token consumption—use it for systematic reviews.",
        "timing": "3 minutes",
        "discussion": "Ask: Which of these techniques will you apply first in your workflow? What's blocking you from adopting it today?",
        "context": "In production, these techniques compound. Fresh context prevents wasted iterations defending bad decisions. Iterative review with tests as the objective arbiter prevents shipping bugs. Dual-optimized PRs make reviews efficient for both humans and AI assistants. CoD makes AI-assisted reviews faster and cheaper.",
        "transition": "Next lesson: Debugging with AI—what happens when tests fail or production breaks, and how to systematically root-cause issues with AI assistance."
      }
    }
  ]
}
